{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo Getting Started Tutorial\n",
    "\n",
    "Bodo is the simplest and most efficient analytics engine. It accelerates and scales data science programs\n",
    "automatically and enables instant deployment, eliminating the need to rewrite Python analytics code to Spark/Scala, SQL or MPI/C++.\n",
    "In this tutorial, we will cover the basics of using Bodo and explain its important concepts.\n",
    "\n",
    "In a nutshell, Bodo provides a just-in-time (JIT) compilation workflow using the `@bodo.jit` decorator. It replaces decorated Python functions with an optimized and parallelized binary version using advanced compilation methods.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Please follow the [Bodo installation](http://docs.bodo.ai/latest/source/install.html) and [Jupyter Notebook Setup](http://docs.bodo.ai/latest/source/jupyter.html) pages to setup the environment. Also, make sure MPI engines are started in the `IPython Clusters` tab (or using `ipcluster start -n 4 --profile=mpi` in command line), then initialize the `ipyparallel` environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client(profile='mpi')\n",
    "view = c[:]\n",
    "view.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Pandas with Bodo\n",
    "First, we demonstrate how Bodo automatically parallelizes and optimizes standard Python programs that make use of pandas and NumPy, without the need to rewrite your code. Bodo can scale your analytics code to thousands of cores, providing orders of magnitude speed up depending on program characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "To begin, let's generate a simple dataset (the size of this dataframe in memory is approximately 305 MB, and the size of the written Parquet file is 77 MB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A         B\n",
      "0          0         0\n",
      "1          1         1\n",
      "2          2         2\n",
      "3          3         3\n",
      "4          4         4\n",
      "...       ..       ...\n",
      "19999995  15  19999995\n",
      "19999996  16  19999996\n",
      "19999997  17  19999997\n",
      "19999998  18  19999998\n",
      "19999999  19  19999999\n",
      "\n",
      "[20000000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NUM_GROUPS = 30\n",
    "NUM_ROWS = 20_000_000\n",
    "df = pd.DataFrame({\n",
    "    \"A\": np.arange(NUM_ROWS) % NUM_GROUPS,\n",
    "    \"B\": np.arange(NUM_ROWS)\n",
    "})\n",
    "df.to_parquet(\"example1.pq\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "Now let's read and process this dataframe. First using Python and pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6666676000003\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    print(m)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run it with Bodo in parallel. To do this, all that we have to do is add the `bodo.jit` decorator to the function, and run the program with MPI (on Jupyter Notebook, use the `%%px --block` *magic* to run on MPI engines):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 6666676000003\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    print(m)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the program appears to be a regular sequential Python program, Bodo compiles and *transforms* the decorated code (the `test` function in this example) under the hood, so that it can run in parallel on many cores. Each core operates on a different chunk of the data and communicates with other cores when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Python Processes\n",
    "With Bodo, all processes are running the same code. Bodo manages parallelism inside `jit` functions to match sequential Python as much as possible. On the other hand, the code outside `jit` functions runs as regular Python on all processes. For example, the code below when run on 4 processes produces 4 prints, one for each Python process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 6666676000003\n",
      "[stdout:1] 6666676000003\n",
      "[stdout:2] 6666676000003\n",
      "[stdout:3] 6666676000003\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    return m\n",
    "\n",
    "m = test()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prints\n",
    "Bodo prints replicated values like `m` only once (on process `0`) to avoid redundant printing, but we can use `bodo.parallel_print` to see prints on all processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 6666676000003\n",
      "[stdout:1] 6666676000003\n",
      "[stdout:2] 6666676000003\n",
      "[stdout:3] 6666676000003\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    bodo.parallel_print(m)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Data Read\n",
    "\n",
    "Bodo can read data from storage such as Parquet files in parallel. This means that each process reads only its own chunk of data (which can be proportionally faster than sequential read). The example below demonstrates parallel read by printing data chunks on different cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "          A        B\n",
      "0         0        0\n",
      "1         1        1\n",
      "2         2        2\n",
      "3         3        3\n",
      "4         4        4\n",
      "...      ..      ...\n",
      "4999995  15  4999995\n",
      "4999996  16  4999996\n",
      "4999997  17  4999997\n",
      "4999998  18  4999998\n",
      "4999999  19  4999999\n",
      "\n",
      "[5000000 rows x 2 columns]\n",
      "[stdout:1] \n",
      "          A        B\n",
      "5000000  20  5000000\n",
      "5000001  21  5000001\n",
      "5000002  22  5000002\n",
      "5000003  23  5000003\n",
      "5000004  24  5000004\n",
      "...      ..      ...\n",
      "9999995   5  9999995\n",
      "9999996   6  9999996\n",
      "9999997   7  9999997\n",
      "9999998   8  9999998\n",
      "9999999   9  9999999\n",
      "\n",
      "[5000000 rows x 2 columns]\n",
      "[stdout:2] \n",
      "           A         B\n",
      "10000000  10  10000000\n",
      "10000001  11  10000001\n",
      "10000002  12  10000002\n",
      "10000003  13  10000003\n",
      "10000004  14  10000004\n",
      "...       ..       ...\n",
      "14999995  25  14999995\n",
      "14999996  26  14999996\n",
      "14999997  27  14999997\n",
      "14999998  28  14999998\n",
      "14999999  29  14999999\n",
      "\n",
      "[5000000 rows x 2 columns]\n",
      "[stdout:3] \n",
      "           A         B\n",
      "15000000   0  15000000\n",
      "15000001   1  15000001\n",
      "15000002   2  15000002\n",
      "15000003   3  15000003\n",
      "15000004   4  15000004\n",
      "...       ..       ...\n",
      "19999995  15  19999995\n",
      "19999996  16  19999996\n",
      "19999997  17  19999997\n",
      "19999998  18  19999998\n",
      "19999999  19  19999999\n",
      "\n",
      "[5000000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    print(df)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at column B, we can clearly see that each process has a separate chunk of the original dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing Computation\n",
    "\n",
    "![Groupby shuffle communication pattern](img/groupby.jpg)\n",
    "\n",
    "Bodo parallelizes computation automatically by dividing the work between cores and performing the necessary data communication. For example, the `groupby` operation in our example needs the data of each group to be on the same processor. This requires *shuffling* data across the cluster. Bodo uses [MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface) for efficient communication, which is usually much faster than alternative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Write\n",
    "\n",
    "Bodo can write data to storage in parallel as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    df2.to_parquet(\"example1-df2.pq\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read and print the results with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                B\n",
      "A                \n",
      "0   6666663333330\n",
      "4   6666665999998\n",
      "6   6666667333332\n",
      "16  6666674000002\n",
      "20  6666656666670\n",
      "24  6666659333334\n",
      "28  6666661999998\n",
      "1   6666663999997\n",
      "7   6666667999999\n",
      "8   6666668666666\n",
      "11  6666670666667\n",
      "12  6666671333334\n",
      "13  6666672000001\n",
      "15  6666673333335\n",
      "18  6666675333336\n",
      "5   6666666666665\n",
      "19  6666676000003\n",
      "21  6666657333336\n",
      "22  6666658000002\n",
      "23  6666658666668\n",
      "29  6666662666664\n",
      "2   6666664666664\n",
      "3   6666665333331\n",
      "9   6666669333333\n",
      "10  6666670000000\n",
      "14  6666672666668\n",
      "17  6666674666669\n",
      "25  6666660000000\n",
      "26  6666660666666\n",
      "27  6666661333332\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"example1-df2.pq\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the `groupby` results generated by Bodo can differ from pandas since Bodo doesn't automatically sort the output distributed data (it is expensive and not necessary in many cases). Users can explicitly sort dataframes at any point if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Data Distribution\n",
    "\n",
    "Bodo automatically distributes data and computation in Bodo functions by analyzing them for parallelization. However, Bodo does not know how input parameters of Bodo functions are distributed, and similarly how the user wants to handle return values. As such, Bodo assumes that input parameters and return values are *replicated* by default, meaning that every process receives the same input data and returns the same output, as opposed to different data chunks.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> The distribution scheme of input parameters and return values determines the distribution scheme for variables inside the Bodo function that depend on them.\n",
    "</div>\n",
    "\n",
    "To illustrate this effect, let's return the `groupby` output from the Bodo function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "                B\n",
      "A                \n",
      "0   6666663333330\n",
      "1   6666663999997\n",
      "2   6666664666664\n",
      "3   6666665333331\n",
      "4   6666665999998\n",
      "5   6666666666665\n",
      "6   6666667333332\n",
      "7   6666667999999\n",
      "8   6666668666666\n",
      "9   6666669333333\n",
      "10  6666670000000\n",
      "11  6666670666667\n",
      "12  6666671333334\n",
      "13  6666672000001\n",
      "14  6666672666668\n",
      "15  6666673333335\n",
      "16  6666674000002\n",
      "17  6666674666669\n",
      "18  6666675333336\n",
      "19  6666676000003\n",
      "20  6666656666670\n",
      "21  6666657333336\n",
      "22  6666658000002\n",
      "23  6666658666668\n",
      "24  6666659333334\n",
      "25  6666660000000\n",
      "26  6666660666666\n",
      "27  6666661333332\n",
      "28  6666661999998\n",
      "29  6666662666664\n",
      "[stdout:1] \n",
      "                B\n",
      "A                \n",
      "0   6666663333330\n",
      "1   6666663999997\n",
      "2   6666664666664\n",
      "3   6666665333331\n",
      "4   6666665999998\n",
      "5   6666666666665\n",
      "6   6666667333332\n",
      "7   6666667999999\n",
      "8   6666668666666\n",
      "9   6666669333333\n",
      "10  6666670000000\n",
      "11  6666670666667\n",
      "12  6666671333334\n",
      "13  6666672000001\n",
      "14  6666672666668\n",
      "15  6666673333335\n",
      "16  6666674000002\n",
      "17  6666674666669\n",
      "18  6666675333336\n",
      "19  6666676000003\n",
      "20  6666656666670\n",
      "21  6666657333336\n",
      "22  6666658000002\n",
      "23  6666658666668\n",
      "24  6666659333334\n",
      "25  6666660000000\n",
      "26  6666660666666\n",
      "27  6666661333332\n",
      "28  6666661999998\n",
      "29  6666662666664\n",
      "[stdout:2] \n",
      "                B\n",
      "A                \n",
      "0   6666663333330\n",
      "1   6666663999997\n",
      "2   6666664666664\n",
      "3   6666665333331\n",
      "4   6666665999998\n",
      "5   6666666666665\n",
      "6   6666667333332\n",
      "7   6666667999999\n",
      "8   6666668666666\n",
      "9   6666669333333\n",
      "10  6666670000000\n",
      "11  6666670666667\n",
      "12  6666671333334\n",
      "13  6666672000001\n",
      "14  6666672666668\n",
      "15  6666673333335\n",
      "16  6666674000002\n",
      "17  6666674666669\n",
      "18  6666675333336\n",
      "19  6666676000003\n",
      "20  6666656666670\n",
      "21  6666657333336\n",
      "22  6666658000002\n",
      "23  6666658666668\n",
      "24  6666659333334\n",
      "25  6666660000000\n",
      "26  6666660666666\n",
      "27  6666661333332\n",
      "28  6666661999998\n",
      "29  6666662666664\n",
      "[stdout:3] \n",
      "                B\n",
      "A                \n",
      "0   6666663333330\n",
      "1   6666663999997\n",
      "2   6666664666664\n",
      "3   6666665333331\n",
      "4   6666665999998\n",
      "5   6666666666665\n",
      "6   6666667333332\n",
      "7   6666667999999\n",
      "8   6666668666666\n",
      "9   6666669333333\n",
      "10  6666670000000\n",
      "11  6666670666667\n",
      "12  6666671333334\n",
      "13  6666672000001\n",
      "14  6666672666668\n",
      "15  6666673333335\n",
      "16  6666674000002\n",
      "17  6666674666669\n",
      "18  6666675333336\n",
      "19  6666676000003\n",
      "20  6666656666670\n",
      "21  6666657333336\n",
      "22  6666658000002\n",
      "23  6666658666668\n",
      "24  6666659333334\n",
      "25  6666660000000\n",
      "26  6666660666666\n",
      "27  6666661333332\n",
      "28  6666661999998\n",
      "29  6666662666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "/bodo/bodo/transforms/distributed_analysis.py:233: BodoWarning: No parallelism found for function 'test'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  \"information.\".format(self.func_ir.func_id.func_name)\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    return df2\n",
    "\n",
    "df2 = test()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `df2` has the same data on every process. Furthermore, Bodo warns that it didn't find any parallelism inside the `test` function. In this example, every process reads the whole input Parquet file and executes the same sequential program. The reason is that Bodo makes sure all variables dependent on `df2` have the same distribution, creating an inverse cascading effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `distributed` Flag\n",
    "\n",
    "The user can tell Bodo what input/output variables should be distributed using the `distributed` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "                B\n",
      "A                \n",
      "0   6666663333330\n",
      "4   6666665999998\n",
      "6   6666667333332\n",
      "16  6666674000002\n",
      "20  6666656666670\n",
      "24  6666659333334\n",
      "28  6666661999998\n",
      "[stdout:1] \n",
      "                B\n",
      "A                \n",
      "1   6666663999997\n",
      "7   6666667999999\n",
      "8   6666668666666\n",
      "11  6666670666667\n",
      "12  6666671333334\n",
      "13  6666672000001\n",
      "15  6666673333335\n",
      "18  6666675333336\n",
      "[stdout:2] \n",
      "                B\n",
      "A                \n",
      "5   6666666666665\n",
      "19  6666676000003\n",
      "21  6666657333336\n",
      "22  6666658000002\n",
      "23  6666658666668\n",
      "29  6666662666664\n",
      "[stdout:3] \n",
      "                B\n",
      "A                \n",
      "2   6666664666664\n",
      "3   6666665333331\n",
      "9   6666669333333\n",
      "10  6666670000000\n",
      "14  6666672666668\n",
      "17  6666674666669\n",
      "25  6666660000000\n",
      "26  6666660666666\n",
      "27  6666661333332\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit(distributed=[\"df2\"])\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    return df2\n",
    "\n",
    "df2 = test()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the program is fully parallelized and chunks of data are returned to Python on different processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic benchmarking of the pandas example\n",
    "Now let's do some basic benchmarking to observe the effect of Bodo's automatic parallelization. Here we are only scaling up to a few cores, but Bodo can scale the same code to thousands of cores in a cluster.\n",
    "\n",
    "Let's add timers and run the code again with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute time: 0.7629697322845459 secs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    t0 = time.time()\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    print(\"Compute time:\", time.time() - t0, \"secs\")\n",
    "    return m\n",
    "\n",
    "result = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's measure Bodo's execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Compute time: 0.15030407905578613 secs\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import time\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    t0 = time.time()\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    print(\"Compute time:\", time.time() - t0, \"secs\")\n",
    "    return m\n",
    "\n",
    "result = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Bodo computes results faster than pandas using parallel computation. The speedup depends on the data and program characteristics, as well as the number of cores used. Usually, we can continue scaling to many more cores as long as the data is large enough.\n",
    "\n",
    "Note how we included timers inside the Bodo function. This avoids measuring compilation time since Bodo compiles each `jit` function the first time it is called. Not measuring compilation time in benchmarking is usually important since:\n",
    "\n",
    "1. Compilation time is often not significant for large computations in real settings but simple benchmarks are designed to run quickly\n",
    "2. Functions can potentially be compiled and cached ahead of execution time\n",
    "3. Compilation happens only once but the same function may be called multiple times, leading to inconsistent measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas User-Defined Functions\n",
    "User-defined functions (UDFs) offer significant flexibility but have high overhead in Pandas. Bodo can accelerate UDFs significantly, allowing flexibility without performance overheads. Let's modify our example to use UDFs and measure  performance again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute time: 3.4350690841674805 secs\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    t0 = time.time()\n",
    "    df2 = df.groupby(\"A\")[\"B\"].agg((lambda a: (a==1).sum(), lambda a: (a==2).sum(), lambda a: (a==3).sum()))\n",
    "    m = df2.mean()\n",
    "    print(\"Compute time:\", time.time() - t0, \"secs\")\n",
    "    return m\n",
    "\n",
    "result = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example with Bodo is significantly faster, even on a single core:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute time: 0.7699737200746313 secs\n"
     ]
    }
   ],
   "source": [
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    t0 = time.time()\n",
    "    df2 = df.groupby(\"A\")[\"B\"].agg((lambda a: (a==1).sum(), lambda a: (a==2).sum(), lambda a: (a==3).sum()))\n",
    "    m = df2.mean()\n",
    "    print(\"Compute time:\", time.time() - t0, \"secs\")\n",
    "    return m\n",
    "\n",
    "result = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo's parallelism improves performance further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Compute time: 0.2205293399747461 secs\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    t0 = time.time()\n",
    "    df2 = df.groupby(\"A\")[\"B\"].agg((lambda a: (a==1).sum(), lambda a: (a==2).sum(), lambda a: (a==3).sum()))\n",
    "    m = df2.mean()\n",
    "    print(\"Compute time:\", time.time() - t0, \"secs\")\n",
    "    return m\n",
    "\n",
    "result = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Optimizations in Bodo\n",
    "Bodo also improves performance by eliminating intermediate array values in computations such as expressions in Pandas and Numpy. The Monte Carlo Pi Estimation example demonstrates this effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 9.244210243225098 \n",
      "result: 3.14168272\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_pi(n):\n",
    "    t1 = time.time()\n",
    "    x = 2 * np.random.ranf(n) - 1\n",
    "    y = 2 * np.random.ranf(n) - 1\n",
    "    pi = 4 * np.sum(x**2 + y**2 < 1) / n\n",
    "    print(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\n",
    "\n",
    "calc_pi(2 * 10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo is faster even on a single core since it avoids creating arrays alltogether:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.1929816810879856 \n",
      "result: 3.14158668\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def calc_pi(n):\n",
    "    t1 = time.time()\n",
    "    x = 2 * np.random.ranf(n) - 1\n",
    "    y = 2 * np.random.ranf(n) - 1\n",
    "    pi = 4 * np.sum(x**2 + y**2 < 1) / n\n",
    "    print(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\n",
    "\n",
    "calc_pi(2 * 10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data-parallel array computations typically scale well too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Execution time: 0.5737681119935587 \n",
      "result: 3.14162074\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import numpy as np\n",
    "\n",
    "@bodo.jit\n",
    "def calc_pi(n):\n",
    "    t1 = time.time()\n",
    "    x = 2 * np.random.ranf(n) - 1\n",
    "    y = 2 * np.random.ranf(n) - 1\n",
    "    pi = 4 * np.sum(x**2 + y**2 < 1) / n\n",
    "    print(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\n",
    "\n",
    "calc_pi(2 * 10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupported Pandas/Python Features\n",
    "### Supported Pandas Operations\n",
    "\n",
    "Bodo supports a large subset of Pandas APIs as listed [here](http://docs.bodo.ai/latest/source/pandas.html). Moreover, dataframe schemas (column names and types) should be stable in operations. For example, key column names to `group` have to be constant for output type to be stable. This example demonstrates the issue:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "BodoError",
     "evalue": "groupby(): 'by' parameter only supports a constant column label or column labels.\n\nFile \"<ipython-input-25-835749d04e4e>\", line 5:\ndef f(a, i):\n    <source elided>\n    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n    return df.groupby(column_list).sum()\n    ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBodoError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-835749d04e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/bodo/bodo/numba_compat.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBodoError\u001b[0m: groupby(): 'by' parameter only supports a constant column label or column labels.\n\nFile \"<ipython-input-25-835749d04e4e>\", line 5:\ndef f(a, i):\n    <source elided>\n    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n    return df.groupby(column_list).sum()\n    ^\n"
     ]
    }
   ],
   "source": [
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def f(a, i):\n",
    "    column_list = a[:i]  # some computation that cannot be inferred statically\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n",
    "    return df.groupby(column_list).sum()\n",
    "\n",
    "a = [\"A\", \"B\"]\n",
    "i = 1\n",
    "f(a, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code can most often be refactored to compute the key list in regular Python and pass as argument to Bodo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bodo/bodo/transforms/distributed_analysis.py:233: BodoWarning: No parallelism found for function 'f'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  \"information.\".format(self.func_ir.func_id.func_name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    B\n",
       "A    \n",
       "1  10\n",
       "2   5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(column_list):\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n",
    "    return df.groupby(column_list).sum()\n",
    "\n",
    "a = [\"A\", \"B\"]\n",
    "i = 1\n",
    "column_list = a[:i]\n",
    "f(column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported Python Operations\n",
    "\n",
    "Bodo relies on Numba for supporting basic Python features. Therefore, Python constructs that are not supported by Numba (see Numba documentation [here](http://numba.pydata.org/numba-doc/latest/reference/pysupported.html)) should be avoided in Bodo programs. For example:\n",
    "\n",
    "- exceptions: `try` .. `except`, `raise`\n",
    "- context manager: `with`\n",
    "- `list`, `set`, `dict` and `generator` comprehensions\n",
    "- `async` features\n",
    "- class definition: `class`\n",
    "- string formatting, e.g. “A: {}”.format(a)\n",
    "- List containing values of heterogeneous type\n",
    "  * myList = [1, \"a\", 0.1]\n",
    "- Dictionary containing values of heterogeneous type\n",
    "  * myDict = {\"A\": 1, \"B\": \"a\", \"C\": 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Data Structures\n",
    "\n",
    "Bodo can parallelize Pandas DataFrame and Series data structures, as well as Numpy arrays. However, collections like lists, sets and dictionaries cannot be parallelized yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
