{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo Getting Started Tutorial\n",
    "\n",
    "Bodo is the simplest and most efficient analytics engine. It accelerates and scales data science programs\n",
    "automatically and enables instant deployment, eliminating the need to rewrite Python analytics code to Spark/Scala, SQL or MPI/C++.\n",
    "In this tutorial, we will cover the basics of using Bodo and explain how it works under the hood.\n",
    "\n",
    "In a nutshell, Bodo provides a just-in-time (JIT) compilation workflow using the `@bodo.jit` decorator. It replaces decorated Python functions with an optimized and parallelized binary version using advanced compilation methods.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "Make sure MPI engines are started in the `IPython Clusters` tab (or using `ipcluster start -n 8 --profile=mpi`), then initialize the `ipyparallel` environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client(profile='mpi')\n",
    "view = c[:]\n",
    "view.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parallel pandas with Bodo\n",
    "First, we will show how Bodo automatically parallelizes, scales and optimizes standard Python programs that make use of pandas and NumPy, without the need to rewrite your code. Bodo can run your Python code on thousands of cores and, depending on the size of your data and the operations that the code performs, it can speed up analytics programs by several orders of magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "To begin, let's generate a simple dataset (the size of this dataframe in memory is approximately 305 MB, and the size of the written Parquet file is 77 MB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B\n",
      "0         0         0\n",
      "1         1         1\n",
      "2         2         2\n",
      "3         3         3\n",
      "4         4         4\n",
      "...      ..       ...\n",
      "19999995  5  19999995\n",
      "19999996  6  19999996\n",
      "19999997  7  19999997\n",
      "19999998  8  19999998\n",
      "19999999  9  19999999\n",
      "\n",
      "[20000000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NUM_GROUPS = 10\n",
    "NUM_ROWS = 20000000\n",
    "A_col = [i % NUM_GROUPS for i in range(NUM_ROWS)]\n",
    "df = pd.DataFrame({\"A\": A_col, \"B\": np.arange(NUM_ROWS)})\n",
    "df.to_parquet(\"example1.pq\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "Now let's read and process this dataframe. First using Python and pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                B\n",
      "A                \n",
      "0  19999990000000\n",
      "1  19999992000000\n",
      "2  19999994000000\n",
      "3  19999996000000\n",
      "4  19999998000000\n",
      "5  20000000000000\n",
      "6  20000002000000\n",
      "7  20000004000000\n",
      "8  20000006000000\n",
      "9  20000008000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    result = df.groupby(\"A\").sum()\n",
    "    return result\n",
    "\n",
    "result = test()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run it with Bodo in parallel. To do this, all that we have to do is add the `bodo.jit` decorator to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "                B\n",
      "A                \n",
      "0  19999990000000\n",
      "4  19999998000000\n",
      "5  20000000000000\n",
      "6  20000002000000\n",
      "[stdout:1] \n",
      "                B\n",
      "A                \n",
      "1  19999992000000\n",
      "2  19999994000000\n",
      "3  19999996000000\n",
      "7  20000004000000\n",
      "8  20000006000000\n",
      "9  20000008000000\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['result'])\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    result = df.groupby(\"A\").sum()\n",
    "    return result\n",
    "\n",
    "result = test()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several things to explain here. We will go over them one by one in the following. At the end, we will do some basic benchmarking of this example and compare performance with pandas.\n",
    "\n",
    "What is important to understand first is how this code is being executed in parallel. If you are running this in a notebook, the `%%px magic` sends the above code for execution on every process (or MPI engine).\n",
    "\n",
    "The main thing to note is that although the program appears to be a regular sequential Python program, Bodo is compiling and *transforming* the decorated code (the `test` function in this example) under the hood, so that it can run in parallel on many cores. There will be many cores running the same code in parallel (which is a transformed version of the original code) and each core will be operating on a different chunk of the data.\n",
    "\n",
    "Although you don't need to understand how Bodo parallelizes, it is important to understand this distinction between a regular Python program and a parallel Bodo program in order to achieve a correct distribution or partitioning of data across processes for effective parallelization. We will explain this below.\n",
    "\n",
    "//The result obtained is the same as pandas but presented differently because each process owns a different part of the data. We will explain this further in a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying data distribution\n",
    "\n",
    "Bodo automatically distributes data and computation in Bodo functions by analyzing them for parallelization. However, Bodo does not know how input parameters of Bodo functions are distributed, and similarly how the user wants to handle return values. As such, by default it makes the assumption that input parameters and return values are *replicated* (that is, every process receives the same input data and returns the same output, as opposed to different data chunks).\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> the distribution scheme of input parameters and return values determines the distribution scheme for variables inside the Bodo function that depend on them.\n",
    "</div>\n",
    "\n",
    "In our above example, if we don't tell Bodo that the return variable is `distributed`, Bodo will assume that the data associated with `result` has to be the same on every process, which has an inverse cascading effect: if that data is on every process, that means the data of `df` is also on every process, which means that the `read_parquet` should be a sequential read of the whole file on every process.\n",
    "\n",
    "To illustrate, let's see what happens if we don't use the `distributed` flag in the decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "                B\n",
      "A                \n",
      "0  19999990000000\n",
      "1  19999992000000\n",
      "2  19999994000000\n",
      "3  19999996000000\n",
      "4  19999998000000\n",
      "5  20000000000000\n",
      "6  20000002000000\n",
      "7  20000004000000\n",
      "8  20000006000000\n",
      "9  20000008000000\n",
      "[stdout:1] \n",
      "                B\n",
      "A                \n",
      "0  19999990000000\n",
      "1  19999992000000\n",
      "2  19999994000000\n",
      "3  19999996000000\n",
      "4  19999998000000\n",
      "5  20000000000000\n",
      "6  20000002000000\n",
      "7  20000004000000\n",
      "8  20000006000000\n",
      "9  20000008000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "/mnt/d/usr/bodo/bodo/transforms/distributed_analysis.py:229: BodoWarning: No parallelism found for function 'test'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    result = df.groupby(\"A\").sum()\n",
    "    return result\n",
    "\n",
    "result = test()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `result` has the same data on every process. Furthermore, Bodo warns that it didn't find any parallelism inside the `test` function. Note that in this case every process reads the whole input Parquet file, and every process is executing the same sequential program, as opposed to doing a computation in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel read\n",
    "When Bodo reads data from a Parquet file, it reads it in parallel and, assuming the data is determined to be distributed as we saw above, each process reads a different chunk of the dataset. This also means that reads can be proportionally faster compared to sequential reading with one process. To illustrate more clearly the effect of reading different chunks, let's print the data that is read by each process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "         A        B\n",
      "0        0        0\n",
      "1        1        1\n",
      "2        2        2\n",
      "3        3        3\n",
      "4        4        4\n",
      "...     ..      ...\n",
      "9999995  5  9999995\n",
      "9999996  6  9999996\n",
      "9999997  7  9999997\n",
      "9999998  8  9999998\n",
      "9999999  9  9999999\n",
      "\n",
      "[10000000 rows x 2 columns]\n",
      "[stdout:1] \n",
      "          A         B\n",
      "10000000  0  10000000\n",
      "10000001  1  10000001\n",
      "10000002  2  10000002\n",
      "10000003  3  10000003\n",
      "10000004  4  10000004\n",
      "...      ..       ...\n",
      "19999995  5  19999995\n",
      "19999996  6  19999996\n",
      "19999997  7  19999997\n",
      "19999998  8  19999998\n",
      "19999999  9  19999999\n",
      "\n",
      "[10000000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import time\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['result'])\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    bodo.parallel_print(df)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at column B, we can clearly see that each process has a separate chunk of the original dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing computation\n",
    "After reading the data, our example performs a groupby operation. Note that the dataset has 10 different groups, and we can see above that all processes have rows belonging to the ten groups. Therefore, computing the groupby in parallel requires data exchange and communication between processes. This is all done and handled automatically by Bodo using [MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface) for efficient communication. MPI is frequently used in large-scale parallel applications and high-performance computing. Bodo performs the groupby using its own parallel implementation of groupby. Likewise, Bodo has efficient parallel implementations of many other NumPy and pandas operators.\n",
    "\n",
    "<span style='background :yellow' > maybe we can explain a bit more about the required data shuffling for groupby and put a figure (-Juan) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel write\n",
    "\n",
    "Let's do a slightly modified version of the program where we now write the results to disk. Bodo writes the results in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    result = df.groupby(\"A\").sum()\n",
    "    result.to_parquet(\"example1-results\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read and print the results with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                B\n",
      "A                \n",
      "0  19999990000000\n",
      "4  19999998000000\n",
      "5  20000000000000\n",
      "6  20000002000000\n",
      "1  19999992000000\n",
      "2  19999994000000\n",
      "3  19999996000000\n",
      "7  20000004000000\n",
      "8  20000006000000\n",
      "9  20000008000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"example1-results\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that we can notice here is that the order of results generated by Bodo can differ from pandas. This is due to the parallel nature of the computation, and because Bodo doesn't automatically sort distributed data (due to it being expensive and not necessary in many cases). Users can always explicitly sort dataframes at any point in their workflow (including inside Bodo functions) if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic benchmarking of the pandas example\n",
    "Now let's do some basic benchmarking to observe the effect of Bodo's automatic parallelization. Here we are only scaling up to a few cores, but Bodo can scale the same code to many nodes in a cluster and thousands of cores.\n",
    "\n",
    "Let's run the code again with pandas, this time including timers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read time: 0.5932414531707764 secs\n",
      "Groupby time: 0.6460061073303223 secs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def test():\n",
    "    t0 = time.time()\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    print(\"Read time:\", time.time() - t0, \"secs\")\n",
    "    t0 = time.time()\n",
    "    result = df.groupby(\"A\").sum()\n",
    "    print(\"Groupby time:\", time.time() - t0, \"secs\")\n",
    "    return result\n",
    "\n",
    "result = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get accurate and consistent timings across runs for Bodo, we put a `bodo.barrier()` before the computation to make sure that all processes start computing at the same time (recall that the groupby requires processes to communicate and shuffle data to do the computation in parallel, so we want to make sure they begin at the same time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Read time: 0.6947760581970215 secs\n",
      "Groupby time: 0.34023189544677734 secs\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import time\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['result'])\n",
    "def test():\n",
    "    t0 = time.time()\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    bodo.barrier()\n",
    "    print(\"Read time:\", time.time() - t0, \"secs\")\n",
    "    t0 = time.time()\n",
    "    result = df.groupby(\"A\").sum()\n",
    "    print(\"Groupby time:\", time.time() - t0, \"secs\")\n",
    "    return result\n",
    "\n",
    "result = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we have included timers inside the Bodo function. We do this because the first time that a Bodo-decorated function is called it needs to be compiled by Bodo. This compilation time is non-negligible but we don't want to include it in measurements because: (i) when doing large computations typically the compilation time is not significant, but the example we are running now executes very quickly; (ii) there are cases where programs repeatedly call the same Bodo function multiple times and we want to get consistent timings. Again, compilation only occurs the first time a function is called. To avoid including compilation time in measurements, we put timers inside the Bodo function.\n",
    "\n",
    "As we can see, Bodo computes results faster than pandas by doing parallel computation. The speedup depends on the number of cores used. We can continue scaling to many more cores as long as the data is large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Distribution\n",
    "\n",
    "In our first example, we saw that Bodo performs parallel computation by having separate chunks of data divided among processes. However, we also saw that there are situations where some data handled by a Bodo function is not divided into chunks. There are are two main ways in which data is distributed:\n",
    "\n",
    "- Replicated: the data associated with the variable is the same on every process.\n",
    "- 1D: the data is divided into chunks (equal or variable size) split along one dimension. For dataframes, the dimension is rows.\n",
    "\n",
    "Variables which are scalar values are always replicated (they cannot be divided among processes).\n",
    "\n",
    "For arrays, dataframes and other collections, the distribution of a variable is determined mostly by the distribution of variables that it depends on, which often leads back to the distribution of the input parameters of the Bodo function and its return value:\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> Bodo cannot infer the distribution scheme of input parameters and return values (this must be indicated by the user using the `distributed` flag) and assumes they are replicated by default.\n",
    "</div>\n",
    "\n",
    "In addition, the distribution scheme of variables also depends on the nature of the parallel computation that produces the value.\n",
    "\n",
    "Let's illustrate with some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following simple example that computes the mean of a dataframe column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 102.07842132239877\n",
      "[stdout:1] 102.07842132239877\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "res = mean_power()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean can be computed in parallel. Different processes can read different chunks of the dataset in parallel, compute the sum for their chunk independently, and then exchange that information with others in order to compute the mean. The result `x` is a scalar value and thus replicated (is available on every process).\n",
    "\n",
    "Note that there is nothing that requires `df` to be replicated:\n",
    "- The replicated value `x` can be obtained from a parallel computation on distributed data.\n",
    "- The mean can be calculated in parallel from distributed chunks of `df`.\n",
    "- `df` comes from a read operation, which can read chunks.\n",
    "\n",
    "For this reason, Bodo automatically determines that the best distribution for `df` is 1D-distributed.\n",
    "\n",
    "We can be confident that this program runs with true parallelism because Bodo does not warn about the lack of parallelism.\n",
    "\n",
    "Note that because `x` is a scalar value which can only be replicated, if you try marking it as distributed with `distributed=['x']` Bodo will throw an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what happens if instead we pass the data into the Bodo function as a function parameter and we don't mark it as distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 102.07842132239877\n",
      "[stdout:1] 102.07842132239877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "/home/juanjose/bodo-master/bodo/transforms/distributed_analysis.py:229: BodoWarning: No parallelism found for function 'mean_power'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power(df):\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "df = pd.read_parquet('cycling_dataset.pq')\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program runs, and returns the same correct value as before, but there is an important difference: *there is no true parallelism!* Bodo shows an explicit warning about this. What is happening is that each process is reading the whole data file and calculating the mean of the data frame independently.\n",
    "\n",
    "*It is important to understand why this is happening.*\n",
    "\n",
    "Bodo acts in this way because we are passing data into a Bodo function but we haven't specified that the data is distributed, so Bodo assumes that it is replicated. Bodo makes this assumption because it is the safe assumption to make when data comes in from Python, in order to guarantee a correct result.\n",
    "\n",
    "In this example, it turns out that it is indeed the correct assumption, because the data is actually replicated. Here we are reading the dataset outside of a Bodo function. Recall that every process (MPI engine) is executing the same code. The `read_parquet` is regular Python code that is being executed on every process to read the same file using pandas.\n",
    "\n",
    "If we do a `var` operation instead of `mean` and specify `distributed=['df']` we can see that the result is different, which is why it is important to tell Bodo what is the actual distribution of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing distributed data into Bodo functions\n",
    "\n",
    "Now you might be wondering how we can pass distributed data from Python into Bodo functions.\n",
    "\n",
    "One way is to read it with Bodo, return it to Python using the `distributed` flag, and pass it to a different Bodo function using the `distributed` flag. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 102.07842132239877\n",
      "[stdout:1] 102.07842132239877\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def read_data():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')    \n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def mean_power(df):\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "df = read_data()\n",
    "# ... we could do some stuff in Python with df now ...\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are reading the data by calling a Bodo function (`read_data`). We are telling Bodo that the return value (which would be replicated by default) is distributed. This means that Bodo will have each process read a separate chunk from the file, and each process will return only that chunk to the encompassing Python code. Again, recall that every process is running a copy of the same code.\n",
    "\n",
    "Then, from Python, we call another Bodo function (`mean_power`) passing it the chunk of data. We need to tell Bodo that this is a chunk as opposed to replicated data, so we use the `distributed` flag.\n",
    "\n",
    "Note how the code runs and Bodo does not warn about lack of parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to pass distributed data into Bodo functions from Python is to read or generate it from one process, and then scatter it to every process using MPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 102.07842132239877\n",
      "[stdout:1] 102.07842132239877\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def mean_power(df):\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "if bodo.get_rank() == 0:\n",
    "    # this executes only on process 0\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    # scatter chunks of df across all processes\n",
    "    df = bodo.scatterv(df)\n",
    "else:\n",
    "    # this executes on every process\n",
    "    # receive my chunk\n",
    "    df = bodo.scatterv(None)\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a common pattern in MPI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pi Example\n",
    "\n",
    "<span style='background :yellow' > I'm not sure about this example. Its value is that it shows very good performance with Bodo and is small, but I'm not sure that it is interesting for most users. Should we keep this, move it somewhere else? or do we still want it at the beginning? (-Juan) </span>\n",
    "\n",
    "Let's start with a simple example, which computes the value of Pi using Monte-Carlo Integration, to get familiar with the execution environment. Here is the Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 8.239847183227539 \n",
      "result: 3.14149874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.14149874"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calc_pi(n):\n",
    "    t1 = time.time()\n",
    "    x = 2 * np.random.ranf(n) - 1\n",
    "    y = 2 * np.random.ranf(n) - 1\n",
    "    pi = 4 * np.sum(x**2 + y**2 < 1) / n\n",
    "    print(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\n",
    "    return pi\n",
    "\n",
    "calc_pi(2 * 10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the @bodo.jit decorator and run it on just one core (without parallel engines):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.248674508999102 \n",
      "result: 3.1414679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1414679"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def calc_pi(n):\n",
    "    t1 = time.time()\n",
    "    x = 2 * np.random.ranf(n) - 1\n",
    "    y = 2 * np.random.ranf(n) - 1\n",
    "    pi = 4 * np.sum(x**2 + y**2 < 1) / n\n",
    "    print(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\n",
    "    return pi\n",
    "\n",
    "calc_pi(2 * 10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see significant speedup due to compiler optimization. Now let's use the parallel engines using the `%%px` magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Execution time: 0.8065992589981761 \n",
      "result: 3.14135774\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import bodo\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "@bodo.jit\n",
    "def calc_pi(n):\n",
    "    t1 = time.time()\n",
    "    x = 2 * np.random.ranf(n) - 1\n",
    "    y = 2 * np.random.ranf(n) - 1\n",
    "    pi = 4 * np.sum(x**2 + y**2 < 1) / n\n",
    "    print(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\n",
    "    return pi\n",
    "\n",
    "p = calc_pi(2 * 10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo automatically parallelizes this code and distributes the work among parallel engines. Hence, we see additional speedup depending on the number of cores used by engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"img/data-parallel.jpg\">\n",
    "\n",
    "## Data-Parallel Operations\n",
    "Many operations in Numpy and Pandas are fully data-parallel, which lets Bodo parallelize them across data blocks without communication between processors.\n",
    "Examples include many math operators, filtering, combining columns, normalization, dropping rows/columns, etc.\n",
    "\n",
    "Let's drop some rows and columns, and create a new column by extracting month from the time column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background :yellow' > This example is either buggy or we have to give a good explanation somewhere on why the result is a chunk and not replicated. I opened an issue about this. (-Juan) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr  speed  month\n",
      "0              0  185.800003       51      3.460000   81  3.459     10\n",
      "2              2  186.399994       38     11.040000   82  3.874     10\n",
      "3              3  186.800003       38     15.180000   83  4.135     10\n",
      "4              4  186.600006       38     19.430000   83  4.250     10\n",
      "12            12  186.199997        0     51.610001   80  3.029     10\n",
      "...          ...         ...      ...           ...  ...    ...    ...\n",
      "1946         551  146.600006       72  11345.559570  133  6.300     10\n",
      "1947         552  147.000000       72  11351.919922  134  6.356     10\n",
      "1948         553  147.399994       99  11358.370117  135  6.452     10\n",
      "1949         554  147.600006       85  11364.919922  136  6.550     10\n",
      "1950         555  147.600006       78  11371.500000  137  6.581     10\n",
      "\n",
      "[1201 rows x 7 columns]\n",
      "[stdout:1] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr  speed  month\n",
      "1951         556  147.600006       78  11378.120117  137  6.621     10\n",
      "1952         557  147.399994       78  11384.839844  138  6.714     10\n",
      "1953         558  147.000000       85  11391.690430  139  6.854     10\n",
      "1954         559  146.600006      110  11398.709961  139  7.022     10\n",
      "1955         560  146.600006       78  11405.849609  140  7.139     10\n",
      "...          ...         ...      ...           ...  ...    ...    ...\n",
      "3858        1088  182.199997        0  21820.580078  110  4.268     10\n",
      "3859        1089  182.199997        0  21824.849609  109  4.268     10\n",
      "3893        1123  178.199997        0  22000.539062   99  3.688     10\n",
      "3894        1124  178.399994       20  22004.210938   99  3.669     10\n",
      "3895        1125  178.399994       80  22007.880859  100  3.669     10\n",
      "\n",
      "[1278 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def data_par():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    df = df[df.power != 0]\n",
    "    df['month'] = df.time.dt.month\n",
    "    df = df.drop(['latitude', 'longitude', 'power', 'time'], axis=1)\n",
    "    #return df.head()\n",
    "    return df\n",
    "\n",
    "res = data_par()\n",
    "#if bodo.get_rank() == 0: display(res)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"img/reduction.jpg\">\n",
    "\n",
    "## Reduction operations\n",
    "\n",
    "<span style='background :yellow' > I used this example for section 3. Thinking of removing this from this tutorial (-Juan) </span>\n",
    "\n",
    "Some operators such as `sum` require a reduction operation across all the data, which implies communication across data blocks. Bodo handles these operations using efficient MPI communication, and makes the output available on all processors.\n",
    "\n",
    "As an example let's compute the mean of the 'power' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 102.07842132239877\n",
      "[stdout:1] 102.07842132239877\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "res = mean_power()\n",
    "#if bodo.get_rank() == 0: display(res)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"img/groupby.jpg\">\n",
    "\n",
    "## GroupBy/Aggregation\n",
    "\n",
    "<span style='background :yellow' > Thinking of removing from this tutorial (-Juan) </span>\n",
    "\n",
    "Grouping operations, which are typically followed by aggregations/reductions, are\n",
    "more challenging for parallel and distributed environments. Bodo uses efficient MPI communication primitives to provide fast and scalable groupby/aggregations.\n",
    "\n",
    "Let's compute the average power output per hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "22    110.625821\n",
       "23     71.754079\n",
       "Name: power, dtype: float64"
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_pm():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    df['hour'] = df.time.dt.hour\n",
    "    grp = df.groupby('hour')\n",
    "    mean_df = grp['power'].mean()\n",
    "    return mean_df.head()\n",
    "\n",
    "res = mean_power_pm()\n",
    "if bodo.get_rank() == 0: display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"img/rolling.jpg\">\n",
    "\n",
    "## Sliding Windows\n",
    "\n",
    "<span style='background :yellow' > Thinking of removing from this tutorial (-Juan) </span>\n",
    "\n",
    "Some popular analytics operations, especially for time-series analysis, are based on sliding windows. Examples include moving averages and percentage change. In a distributed setup, these require communication beyond map-reduce (which is the basis of most systems such as Spark). Bodo handles these cases using efficient patterns known from HPC.\n",
    "\n",
    "Let's compute the moving average of the heart-rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3    82.0\n",
       "4    82.5\n",
       "Name: hr, dtype: float64"
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mov_avg():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    mv_av = df.hr.rolling(4).mean()\n",
    "    return mv_av.head()\n",
    "\n",
    "res = mov_avg()\n",
    "if bodo.get_rank() == 0: display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join\n",
    "\n",
    "<span style='background :yellow' > Thinking of removing from this tutorial (-Juan) </span>\n",
    "\n",
    "Bodo can also efficiently join dataframes, which uses a communication pattern similar to Groupby.\n",
    "\n",
    "Let's read data, split into 2 dataframes and re-join on time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>altitude</th>\n",
       "      <th>cadence</th>\n",
       "      <th>distance</th>\n",
       "      <th>hr</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>power</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186.600006</td>\n",
       "      <td>0</td>\n",
       "      <td>23.860001</td>\n",
       "      <td>84</td>\n",
       "      <td>2016-10-20 22:01:31</td>\n",
       "      <td>30.313130</td>\n",
       "      <td>-97.732724</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.600006</td>\n",
       "      <td>0</td>\n",
       "      <td>28.350000</td>\n",
       "      <td>84</td>\n",
       "      <td>2016-10-20 22:01:32</td>\n",
       "      <td>30.313093</td>\n",
       "      <td>-97.732723</td>\n",
       "      <td>0</td>\n",
       "      <td>4.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186.600006</td>\n",
       "      <td>0</td>\n",
       "      <td>32.970001</td>\n",
       "      <td>83</td>\n",
       "      <td>2016-10-20 22:01:33</td>\n",
       "      <td>30.313050</td>\n",
       "      <td>-97.732717</td>\n",
       "      <td>0</td>\n",
       "      <td>4.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186.600006</td>\n",
       "      <td>0</td>\n",
       "      <td>37.560001</td>\n",
       "      <td>84</td>\n",
       "      <td>2016-10-20 22:01:34</td>\n",
       "      <td>30.313011</td>\n",
       "      <td>-97.732702</td>\n",
       "      <td>0</td>\n",
       "      <td>4.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186.199997</td>\n",
       "      <td>70</td>\n",
       "      <td>86.339996</td>\n",
       "      <td>88</td>\n",
       "      <td>2016-10-20 22:01:46</td>\n",
       "      <td>30.312580</td>\n",
       "      <td>-97.732621</td>\n",
       "      <td>109</td>\n",
       "      <td>5.553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     altitude  cadence   distance  hr                time   latitude  \\\n",
       "0  186.600006        0  23.860001  84 2016-10-20 22:01:31  30.313130   \n",
       "1  186.600006        0  28.350000  84 2016-10-20 22:01:32  30.313093   \n",
       "2  186.600006        0  32.970001  83 2016-10-20 22:01:33  30.313050   \n",
       "3  186.600006        0  37.560001  84 2016-10-20 22:01:34  30.313011   \n",
       "4  186.199997       70  86.339996  88 2016-10-20 22:01:46  30.312580   \n",
       "\n",
       "   longitude  power  speed  \n",
       "0 -97.732724      0  4.435  \n",
       "1 -97.732723      0  4.490  \n",
       "2 -97.732717      0  4.621  \n",
       "3 -97.732702      0  4.591  \n",
       "4 -97.732621    109  5.553  "
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def merge_dfs():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    df1 = df[['altitude', 'cadence', 'distance', 'hr', 'time']]\n",
    "    df2 = df[['latitude', 'longitude', 'power', 'speed', 'time']]\n",
    "    df3 = df1.merge(df2, on='time')\n",
    "    return df3.head()\n",
    "\n",
    "res = merge_dfs()\n",
    "if bodo.get_rank() == 0: display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Distribution\n",
    "\n",
    "<span style='background :yellow' > This is not needed anymore as I have explained it in section 3, but maybe there is still material here to be merged there or kept in the in-depth tutorial (-Juan) </span>\n",
    "\n",
    "Bodo automatically distributes data and computation of the target function by analyzing it for parallelization. It chooses the best and *safest* possible distribution. For example, returning distributed data is not necessary *safe*, since the code outside of the bodo scope would need to handle chunks of data instead of the full data. Consider the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "(3902, 10)\n",
      "Distributed diagnostics for function read_pq, <ipython-input-76-70a5aeb5d795> (1)\n",
      "\n",
      "Data distributions:\n",
      "   Unnamed: 0.77403           REP\n",
      "   altitude.77404             REP\n",
      "   cadence.77405              REP\n",
      "   distance.77406             REP\n",
      "   hr.77407                   REP\n",
      "   latitude.77408             REP\n",
      "   longitude.77409            REP\n",
      "   power.77410                REP\n",
      "   speed.77411                REP\n",
      "   time.77412                 REP\n",
      "   __index_level_0__.77413    REP\n",
      "   $0.15.77429                [<Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>]\n",
      "   $0.23.77539                REP\n",
      "   $df.77578                  REP\n",
      "   $0.6                       REP\n",
      "\n",
      "Parfor distributions:\n",
      "No parfors to distribute.\n",
      "\n",
      "Distributed listing for function read_pq, <ipython-input-76-70a5aeb5d795> (1)\n",
      "--------------------------------------------------| parfor_id/variable: distribution\n",
      "@bodo.jit                                         | \n",
      "def read_pq():                                    | \n",
      "    df = pd.read_parquet('cycling_dataset.pq')----| Unnamed: 0.77403: REP, altitude.77404: REP, cadence.77405: REP, distance.77406: REP, hr.77407: REP, latitude.77408: REP, longitude.77409: REP, power.77410: REP, speed.77411: REP, time.77412: REP, __index_level_0__.77413: REP, $0.15.77429: [<Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>, <Distribution.REP: 1>], $0.23.77539: REP, $df.77578: REP\n",
      "    return df-------------------------------------| $0.6: REP\n",
      "\n",
      "Distributed analysis replicated output variable $0.6. Set distributed flag for the original variable if distributed partitions should be returned.\n",
      "\n",
      "[stdout:1] (3902, 10)\n",
      "[stdout:2] (3902, 10)\n",
      "[stdout:3] (3902, 10)\n",
      "[stdout:4] (3902, 10)\n",
      "[stdout:5] (3902, 10)\n",
      "[stdout:6] (3902, 10)\n",
      "[stdout:7] (3902, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "/Users/ehsan/dev/bodo/bodo/transforms/distributed_analysis.py:240: BodoWarning: No parallelism found for function 'read_pq'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  \"information.\".format(self.func_ir.func_id.func_name)\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def read_pq():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return df\n",
    "\n",
    "df = read_pq()\n",
    "print(df.shape)\n",
    "if bodo.get_rank() == 0: read_pq.distributed_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `distributed_diagnostics` function prints diagnostics information about distribution analysis by Bodo. In this case, all variables are assigned the `REP` distribution, which means they are replicated and there is no distribution of data. The reason is the return of `df`, which also propagates `REP` to all other variables since they are involved in parallel computation with `df`.\n",
    "\n",
    "We can change this behavior by a simple annotation for `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "(488, 10)\n",
      "Distributed diagnostics for function read_pq, <ipython-input-77-cdd5d7a9c9a3> (1)\n",
      "\n",
      "Data distributions:\n",
      "   Unnamed: 0.77776            1D_Block\n",
      "   altitude.77777              1D_Block\n",
      "   cadence.77778               1D_Block\n",
      "   distance.77779              1D_Block\n",
      "   hr.77780                    1D_Block\n",
      "   latitude.77781              1D_Block\n",
      "   longitude.77782             1D_Block\n",
      "   power.77783                 1D_Block\n",
      "   speed.77784                 1D_Block\n",
      "   time.77785                  1D_Block\n",
      "   __index_level_0__.77786     1D_Block\n",
      "   $0.15.77802                 [<Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>]\n",
      "   $0.23.77922                 1D_Block\n",
      "   $df.77964                   1D_Block\n",
      "   distributed_return.77845    1D_Block\n",
      "   $dist_return.77842.77965    1D_Block\n",
      "\n",
      "Parfor distributions:\n",
      "No parfors to distribute.\n",
      "\n",
      "Distributed listing for function read_pq, <ipython-input-77-cdd5d7a9c9a3> (1)\n",
      "--------------------------------------------------| parfor_id/variable: distribution\n",
      "@bodo.jit(distributed=['df'])                     | \n",
      "def read_pq():                                    | \n",
      "    df = pd.read_parquet('cycling_dataset.pq')----| Unnamed: 0.77776: 1D_Block, altitude.77777: 1D_Block, cadence.77778: 1D_Block, distance.77779: 1D_Block, hr.77780: 1D_Block, latitude.77781: 1D_Block, longitude.77782: 1D_Block, power.77783: 1D_Block, speed.77784: 1D_Block, time.77785: 1D_Block, __index_level_0__.77786: 1D_Block, $0.15.77802: [<Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>, <Distribution.OneD: 5>], $0.23.77922: 1D_Block, $df.77964: 1D_Block\n",
      "    return df-------------------------------------| distributed_return.77845: 1D_Block\n",
      "\n",
      "\n",
      "[stdout:1] (488, 10)\n",
      "[stdout:2] (488, 10)\n",
      "[stdout:3] (488, 10)\n",
      "[stdout:4] (488, 10)\n",
      "[stdout:5] (488, 10)\n",
      "[stdout:6] (488, 10)\n",
      "[stdout:7] (486, 10)\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def read_pq():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return df\n",
    "\n",
    "df = read_pq()\n",
    "print(df.shape)\n",
    "if bodo.get_rank() == 0: read_pq.distributed_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, all variables are assigned the `1D_Block` distribution, which means they are divided in equal chunks among processors. The returned dataframe on each processor is therefore a chunk of the full dataset. This is useful, for example, when computation on chunks is desired outside the scope of Bodo (e.g. mixing Bodo code with custom non-Bodo code and other packages like TensorFlow). In general, the `distributed` flag can be used for both passing distributed chunks as input argument, as well as returning distributed chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
