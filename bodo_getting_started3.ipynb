{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo Getting Started Tutorial\n",
    "\n",
    "Bodo is the simplest and most efficient analytics engine. It accelerates and scales data science programs\n",
    "automatically and enables instant deployment, eliminating the need to rewrite Python analytics code to Spark/Scala, SQL or MPI/C++.\n",
    "In this tutorial, we will cover the basics of using Bodo and explain how it works under the hood.\n",
    "\n",
    "In a nutshell, Bodo provides a just-in-time (JIT) compilation workflow using the `@bodo.jit` decorator. It replaces decorated Python functions with an optimized and parallelized binary version using advanced compilation methods.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Please follow the [bodo installation](http://docs.bodo.ai/latest/source/install.html) and [Jupyter Notebook Setup](http://docs.bodo.ai/latest/source/jupyter.html) pages to setup the environment. Also, make sure MPI engines are started in the `IPython Clusters` tab (or using `ipcluster start -n 8 --profile=mpi` in command line), then initialize the `ipyparallel` environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client(profile='mpi')\n",
    "view = c[:]\n",
    "view.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel pandas with Bodo\n",
    "First, we demonstrate how Bodo automatically parallelizes and optimizes standard Python programs that make use of pandas and NumPy, without the need to rewrite your code. Bodo can scale your analytics code to thousands of cores, providing orders of magnitude speed up depending on program characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "To begin, let's generate a simple dataset (the size of this dataframe in memory is approximately 305 MB, and the size of the written Parquet file is 77 MB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A         B\n",
      "0         11         0\n",
      "1         16         1\n",
      "2         18         2\n",
      "3          9         3\n",
      "4         25         4\n",
      "...       ..       ...\n",
      "19999995  12  19999995\n",
      "19999996  22  19999996\n",
      "19999997   3  19999997\n",
      "19999998   2  19999998\n",
      "19999999  11  19999999\n",
      "\n",
      "[20000000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NUM_GROUPS = 30\n",
    "NUM_ROWS = 20_000_000\n",
    "df = pd.DataFrame({\n",
    "    \"A\": np.random.randint(0, NUM_GROUPS, NUM_ROWS),\n",
    "    \"B\": np.arange(NUM_ROWS)\n",
    "})\n",
    "df.to_parquet(\"example1.pq\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "Now let's read and process this dataframe. First using Python and pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6684404478993\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    print(m)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run it with Bodo in parallel. To do this, all that we have to do is add the `bodo.jit` decorator to the function, and use the `%%px --block` *magic* of Jupyter (to run on MPI engines):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 6684404478993.0\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    print(m)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the program appears to be a regular sequential Python program, Bodo compiles and *transforms* the decorated code (the `test` function in this example) under the hood, so that it can run in parallel on many cores. Each core operates on a different chunk of the data and communicates with other cores when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Python Processes\n",
    "Bodo manages parallelism inside `jit` functions to match sequential Python as much as possible. For example, even though the previous code runs on 8 processes, the output print happens only once. On the other hand, the code outside `jit` functions runs as regular Python on all processes. For example, the code below produces 8 prints, one for each Python process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 6684404478993.0\n",
      "[stdout:1] 6684404478993.0\n",
      "[stdout:2] 6684404478993.0\n",
      "[stdout:3] 6684404478993.0\n",
      "[stdout:4] 6684404478993.0\n",
      "[stdout:5] 6684404478993.0\n",
      "[stdout:6] 6684404478993.0\n",
      "[stdout:7] 6684404478993.0\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    return m\n",
    "\n",
    "m = test()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Data Read\n",
    "\n",
    "Bodo can read data from storage such as Parquet files in parallel. This means that each process reads only its own chunk of data (which can be proportionally faster than sequential read). The example below demonstrates parallel read by printing data chunks on different cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "          A        B\n",
      "0        11        0\n",
      "1        16        1\n",
      "2        18        2\n",
      "3         9        3\n",
      "4        25        4\n",
      "...      ..      ...\n",
      "2499995   2  2499995\n",
      "2499996  20  2499996\n",
      "2499997   2  2499997\n",
      "2499998   3  2499998\n",
      "2499999  19  2499999\n",
      "\n",
      "[2500000 rows x 2 columns]\n",
      "[stdout:1] \n",
      "          A        B\n",
      "2500000  25  2500000\n",
      "2500001  23  2500001\n",
      "2500002   7  2500002\n",
      "2500003  25  2500003\n",
      "2500004  24  2500004\n",
      "...      ..      ...\n",
      "4999995   1  4999995\n",
      "4999996   2  4999996\n",
      "4999997  12  4999997\n",
      "4999998  12  4999998\n",
      "4999999   3  4999999\n",
      "\n",
      "[2500000 rows x 2 columns]\n",
      "[stdout:2] \n",
      "          A        B\n",
      "5000000   0  5000000\n",
      "5000001  26  5000001\n",
      "5000002  21  5000002\n",
      "5000003   3  5000003\n",
      "5000004  27  5000004\n",
      "...      ..      ...\n",
      "7499995  17  7499995\n",
      "7499996  11  7499996\n",
      "7499997  13  7499997\n",
      "7499998  15  7499998\n",
      "7499999  20  7499999\n",
      "\n",
      "[2500000 rows x 2 columns]\n",
      "[stdout:3] \n",
      "          A        B\n",
      "7500000  22  7500000\n",
      "7500001  10  7500001\n",
      "7500002  24  7500002\n",
      "7500003   8  7500003\n",
      "7500004   9  7500004\n",
      "...      ..      ...\n",
      "9999995   0  9999995\n",
      "9999996  23  9999996\n",
      "9999997   3  9999997\n",
      "9999998  14  9999998\n",
      "9999999  14  9999999\n",
      "\n",
      "[2500000 rows x 2 columns]\n",
      "[stdout:4] \n",
      "           A         B\n",
      "10000000  22  10000000\n",
      "10000001  29  10000001\n",
      "10000002  18  10000002\n",
      "10000003  25  10000003\n",
      "10000004   6  10000004\n",
      "...       ..       ...\n",
      "12499995   3  12499995\n",
      "12499996  21  12499996\n",
      "12499997  10  12499997\n",
      "12499998  14  12499998\n",
      "12499999   1  12499999\n",
      "\n",
      "[2500000 rows x 2 columns]\n",
      "[stdout:5] \n",
      "           A         B\n",
      "12500000  23  12500000\n",
      "12500001  22  12500001\n",
      "12500002   9  12500002\n",
      "12500003   6  12500003\n",
      "12500004   4  12500004\n",
      "...       ..       ...\n",
      "14999995  26  14999995\n",
      "14999996   6  14999996\n",
      "14999997  28  14999997\n",
      "14999998  20  14999998\n",
      "14999999  18  14999999\n",
      "\n",
      "[2500000 rows x 2 columns]\n",
      "[stdout:6] \n",
      "           A         B\n",
      "15000000   6  15000000\n",
      "15000001  21  15000001\n",
      "15000002  10  15000002\n",
      "15000003   8  15000003\n",
      "15000004  17  15000004\n",
      "...       ..       ...\n",
      "17499995  15  17499995\n",
      "17499996  11  17499996\n",
      "17499997  25  17499997\n",
      "17499998  24  17499998\n",
      "17499999  26  17499999\n",
      "\n",
      "[2500000 rows x 2 columns]\n",
      "[stdout:7] \n",
      "           A         B\n",
      "17500000  14  17500000\n",
      "17500001   0  17500001\n",
      "17500002   3  17500002\n",
      "17500003  22  17500003\n",
      "17500004  28  17500004\n",
      "...       ..       ...\n",
      "19999995  12  19999995\n",
      "19999996  22  19999996\n",
      "19999997   3  19999997\n",
      "19999998   2  19999998\n",
      "19999999  11  19999999\n",
      "\n",
      "[2500000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    print(df)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at column B, we can clearly see that each process has a separate chunk of the original dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"img/groupby.jpg\">\n",
    "\n",
    "### Parallelizing Computation\n",
    "\n",
    "Bodo parallelizes computation automatically by dividing the work between cores and performing the necessary data communication. For example, the `groupby` operation in our example needs the data of each group to be on the same processor. This requires *shuffling* data across the cluster. Bodo uses [MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface) for efficient communication, which is usually much faster than alternative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Write\n",
    "\n",
    "Bodo can write data to storage in parallel as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    df2.to_parquet(\"example1-df2.pq\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read and print the results with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                B\n",
      "A                \n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "24  6666669522380\n",
      "6   6669013038677\n",
      "4   6658128085633\n",
      "18  6656980845035\n",
      "8   6663814943031\n",
      "15  6659418554747\n",
      "13  6655276574590\n",
      "19  6658728940063\n",
      "21  6667581375427\n",
      "22  6649556088061\n",
      "9   6649522716000\n",
      "27  6669589988049\n",
      "26  6655304463161\n",
      "3   6659645100063\n",
      "2   6666548164072\n",
      "16  6670285154224\n",
      "0   6667636488372\n",
      "11  6680488658607\n",
      "12  6678417438832\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "29  6668872325952\n",
      "23  6674709585510\n",
      "5   6680301445070\n",
      "25  6664124914413\n",
      "14  6684404478993\n",
      "10  6677703432545\n",
      "17  6677274242317\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"example1-df2.pq\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the `groupby` results generated by Bodo can differ from pandas since Bodo doesn't automatically sort the output distributed data (it is expensive and not necessary in many cases). Users can explicitly sort dataframes at any point if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Data Distribution\n",
    "\n",
    "Bodo automatically distributes data and computation in Bodo functions by analyzing them for parallelization. However, Bodo does not know how input parameters of Bodo functions are distributed, and similarly how the user wants to handle return values. As such, Bodo assumes that input parameters and return values are *replicated* by default, meaning that every process receives the same input data and returns the same output, as opposed to different data chunks.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> the distribution scheme of input parameters and return values determines the distribution scheme for variables inside the Bodo function that depend on them.\n",
    "</div>\n",
    "\n",
    "To illustrate this effect, let's return the `groupby` output from the Bodo function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "                B\n",
      "A                \n",
      "11  6680488658607\n",
      "16  6670285154224\n",
      "18  6656980845035\n",
      "9   6649522716000\n",
      "25  6664124914413\n",
      "12  6678417438832\n",
      "0   6667636488372\n",
      "14  6684404478993\n",
      "27  6669589988049\n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "8   6663814943031\n",
      "26  6655304463161\n",
      "19  6658728940063\n",
      "24  6666669522380\n",
      "29  6668872325952\n",
      "3   6659645100063\n",
      "23  6674709585510\n",
      "21  6667581375427\n",
      "10  6677703432545\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "5   6680301445070\n",
      "15  6659418554747\n",
      "6   6669013038677\n",
      "13  6655276574590\n",
      "4   6658128085633\n",
      "2   6666548164072\n",
      "22  6649556088061\n",
      "17  6677274242317\n",
      "[stdout:1] \n",
      "                B\n",
      "A                \n",
      "11  6680488658607\n",
      "16  6670285154224\n",
      "18  6656980845035\n",
      "9   6649522716000\n",
      "25  6664124914413\n",
      "12  6678417438832\n",
      "0   6667636488372\n",
      "14  6684404478993\n",
      "27  6669589988049\n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "8   6663814943031\n",
      "26  6655304463161\n",
      "19  6658728940063\n",
      "24  6666669522380\n",
      "29  6668872325952\n",
      "3   6659645100063\n",
      "23  6674709585510\n",
      "21  6667581375427\n",
      "10  6677703432545\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "5   6680301445070\n",
      "15  6659418554747\n",
      "6   6669013038677\n",
      "13  6655276574590\n",
      "4   6658128085633\n",
      "2   6666548164072\n",
      "22  6649556088061\n",
      "17  6677274242317\n",
      "[stdout:2] \n",
      "                B\n",
      "A                \n",
      "11  6680488658607\n",
      "16  6670285154224\n",
      "18  6656980845035\n",
      "9   6649522716000\n",
      "25  6664124914413\n",
      "12  6678417438832\n",
      "0   6667636488372\n",
      "14  6684404478993\n",
      "27  6669589988049\n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "8   6663814943031\n",
      "26  6655304463161\n",
      "19  6658728940063\n",
      "24  6666669522380\n",
      "29  6668872325952\n",
      "3   6659645100063\n",
      "23  6674709585510\n",
      "21  6667581375427\n",
      "10  6677703432545\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "5   6680301445070\n",
      "15  6659418554747\n",
      "6   6669013038677\n",
      "13  6655276574590\n",
      "4   6658128085633\n",
      "2   6666548164072\n",
      "22  6649556088061\n",
      "17  6677274242317\n",
      "[stdout:3] \n",
      "                B\n",
      "A                \n",
      "11  6680488658607\n",
      "16  6670285154224\n",
      "18  6656980845035\n",
      "9   6649522716000\n",
      "25  6664124914413\n",
      "12  6678417438832\n",
      "0   6667636488372\n",
      "14  6684404478993\n",
      "27  6669589988049\n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "8   6663814943031\n",
      "26  6655304463161\n",
      "19  6658728940063\n",
      "24  6666669522380\n",
      "29  6668872325952\n",
      "3   6659645100063\n",
      "23  6674709585510\n",
      "21  6667581375427\n",
      "10  6677703432545\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "5   6680301445070\n",
      "15  6659418554747\n",
      "6   6669013038677\n",
      "13  6655276574590\n",
      "4   6658128085633\n",
      "2   6666548164072\n",
      "22  6649556088061\n",
      "17  6677274242317\n",
      "[stdout:4] \n",
      "                B\n",
      "A                \n",
      "11  6680488658607\n",
      "16  6670285154224\n",
      "18  6656980845035\n",
      "9   6649522716000\n",
      "25  6664124914413\n",
      "12  6678417438832\n",
      "0   6667636488372\n",
      "14  6684404478993\n",
      "27  6669589988049\n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "8   6663814943031\n",
      "26  6655304463161\n",
      "19  6658728940063\n",
      "24  6666669522380\n",
      "29  6668872325952\n",
      "3   6659645100063\n",
      "23  6674709585510\n",
      "21  6667581375427\n",
      "10  6677703432545\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "5   6680301445070\n",
      "15  6659418554747\n",
      "6   6669013038677\n",
      "13  6655276574590\n",
      "4   6658128085633\n",
      "2   6666548164072\n",
      "22  6649556088061\n",
      "17  6677274242317\n",
      "[stdout:5] \n",
      "                B\n",
      "A                \n",
      "11  6680488658607\n",
      "16  6670285154224\n",
      "18  6656980845035\n",
      "9   6649522716000\n",
      "25  6664124914413\n",
      "12  6678417438832\n",
      "0   6667636488372\n",
      "14  6684404478993\n",
      "27  6669589988049\n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "8   6663814943031\n",
      "26  6655304463161\n",
      "19  6658728940063\n",
      "24  6666669522380\n",
      "29  6668872325952\n",
      "3   6659645100063\n",
      "23  6674709585510\n",
      "21  6667581375427\n",
      "10  6677703432545\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "5   6680301445070\n",
      "15  6659418554747\n",
      "6   6669013038677\n",
      "13  6655276574590\n",
      "4   6658128085633\n",
      "2   6666548164072\n",
      "22  6649556088061\n",
      "17  6677274242317\n",
      "[stdout:6] \n",
      "                B\n",
      "A                \n",
      "11  6680488658607\n",
      "16  6670285154224\n",
      "18  6656980845035\n",
      "9   6649522716000\n",
      "25  6664124914413\n",
      "12  6678417438832\n",
      "0   6667636488372\n",
      "14  6684404478993\n",
      "27  6669589988049\n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "8   6663814943031\n",
      "26  6655304463161\n",
      "19  6658728940063\n",
      "24  6666669522380\n",
      "29  6668872325952\n",
      "3   6659645100063\n",
      "23  6674709585510\n",
      "21  6667581375427\n",
      "10  6677703432545\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "5   6680301445070\n",
      "15  6659418554747\n",
      "6   6669013038677\n",
      "13  6655276574590\n",
      "4   6658128085633\n",
      "2   6666548164072\n",
      "22  6649556088061\n",
      "17  6677274242317\n",
      "[stdout:7] \n",
      "                B\n",
      "A                \n",
      "11  6680488658607\n",
      "16  6670285154224\n",
      "18  6656980845035\n",
      "9   6649522716000\n",
      "25  6664124914413\n",
      "12  6678417438832\n",
      "0   6667636488372\n",
      "14  6684404478993\n",
      "27  6669589988049\n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "8   6663814943031\n",
      "26  6655304463161\n",
      "19  6658728940063\n",
      "24  6666669522380\n",
      "29  6668872325952\n",
      "3   6659645100063\n",
      "23  6674709585510\n",
      "21  6667581375427\n",
      "10  6677703432545\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "5   6680301445070\n",
      "15  6659418554747\n",
      "6   6669013038677\n",
      "13  6655276574590\n",
      "4   6658128085633\n",
      "2   6666548164072\n",
      "22  6649556088061\n",
      "17  6677274242317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "/Users/ehsan/dev/bodo/bodo/transforms/distributed_analysis.py:229: BodoWarning: No parallelism found for function 'test'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    return df2\n",
    "\n",
    "df2 = test()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `df2` has the same data on every process. Furthermore, Bodo warns that it didn't find any parallelism inside the `test` function. In this example, every process reads the whole input Parquet file and executes the same sequential program. The reason is that Bodo makes sure all variables dependent on `df2` have the same distribution, creating an inverse cascading effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `distributed` Flag\n",
    "\n",
    "The user can tell Bodo what input/output variables should be distributed using the `distributed` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "                B\n",
      "A                \n",
      "28  6670905246730\n",
      "20  6665595173997\n",
      "24  6666669522380\n",
      "6   6669013038677\n",
      "4   6658128085633\n",
      "[stdout:1] \n",
      "                B\n",
      "A                \n",
      "18  6656980845035\n",
      "8   6663814943031\n",
      "15  6659418554747\n",
      "13  6655276574590\n",
      "[stdout:2] \n",
      "                B\n",
      "A                \n",
      "19  6658728940063\n",
      "21  6667581375427\n",
      "22  6649556088061\n",
      "[stdout:3] \n",
      "                B\n",
      "A                \n",
      "9   6649522716000\n",
      "27  6669589988049\n",
      "26  6655304463161\n",
      "3   6659645100063\n",
      "2   6666548164072\n",
      "[stdout:4] \n",
      "                B\n",
      "A                \n",
      "16  6670285154224\n",
      "0   6667636488372\n",
      "[stdout:5] \n",
      "                B\n",
      "A                \n",
      "11  6680488658607\n",
      "12  6678417438832\n",
      "7   6667061548203\n",
      "1   6666431467246\n",
      "[stdout:6] \n",
      "                B\n",
      "A                \n",
      "29  6668872325952\n",
      "23  6674709585510\n",
      "5   6680301445070\n",
      "[stdout:7] \n",
      "                B\n",
      "A                \n",
      "25  6664124914413\n",
      "14  6684404478993\n",
      "10  6677703432545\n",
      "17  6677274242317\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit(distributed=[\"df2\"])\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    return df2\n",
    "\n",
    "df2 = test()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the program is fully parallelized and chunks of data are returned to Python on different processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic benchmarking of the pandas example\n",
    "Now let's do some basic benchmarking to observe the effect of Bodo's automatic parallelization. Here we are only scaling up to a few cores, but Bodo can scale the same code to thousands of cores in a cluster.\n",
    "\n",
    "Let's add timers and run the code again with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute time: 0.48606395721435547 secs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    t0 = time.time()\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    print(\"Compute time:\", time.time() - t0, \"secs\")\n",
    "    return m\n",
    "\n",
    "result = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's measure Bodo's execution time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Compute time: 0.21879451999848243 secs\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import time\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def test():\n",
    "    df = pd.read_parquet(\"example1.pq\")\n",
    "    t0 = time.time()\n",
    "    df2 = df.groupby(\"A\").sum()\n",
    "    m = df2.B.max()\n",
    "    print(\"Compute time:\", time.time() - t0, \"secs\")\n",
    "    return m\n",
    "\n",
    "result = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Bodo computes results faster than pandas using parallel computation. The speedup depends on the data and program characteristics, as well as the number of cores used. Usually, we can continue scaling to many more cores as long as the data is large enough.\n",
    "\n",
    "Note how we included timers inside the Bodo function. This avoids measuring compilation time since Bodo compiles each `jit` function the first time it is called. Not measuring compilation time in benchmarking is usually important since:\n",
    "\n",
    "1. Compilation time is often not significant for large computations in real settings but simple benchmarks are designed to run quickly\n",
    "2. Functions can potentially be compiled and cached ahead of execution time\n",
    "3. Compilation happens only once but the same function may be called multiple times, leading to inconsistent measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
