{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo Extended Tutorial\n",
    "\n",
    "This is a continuation of the \"Getting Started\" tutorial. You are encouraged to visit that tutorial first if you have not done so already. In this tutorial, we will explain core Bodo concepts in more detail, introduce more Bodo features, and discuss more advanced topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Please follow the [bodo installation](http://docs.bodo.ai/latest/source/install.html) and [Jupyter Notebook Setup](http://docs.bodo.ai/latest/source/jupyter.html) pages to setup the environment. Also, make sure MPI engines are started in the `IPython Clusters` tab (or using `ipcluster start -n 4 --profile=mpi` in command line)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bodo Basics\n",
    "\n",
    "## JIT (Just-in-time) Compilation Workflow\n",
    "\n",
    "Bodo provides a just-in-time (JIT) compilation workflow using the `@bodo.jit` decorator, which replaces a Python function with a so-called `Dispatcher` object. Bodo compiles the function the first time a Dispatcher object is called and reuses the compiled version afterwards. The function is recompiled only if the same function is called with different argument types (not often in practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def f(n, a):\n",
    "    df = pd.DataFrame({'A': np.arange(n) + a})\n",
    "    return df.head(3)\n",
    "\n",
    "print(f)\n",
    "print(f(8, 1))  # compiles for (int, int) input types\n",
    "print(f(8, 2))  # same input types, no need to compile\n",
    "print(f(8, 2.2))  # compiles for (int, float) input types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this is completely transparent to the caller, and does not affect any Python code calling the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Execution Model\n",
    "\n",
    "As we saw in the \"Getting Started\" tutorial, Bodo transforms functions for parallel execution. However, the dispatcher does not launch processes or threads on the fly. Instead, the Python application (including non-Bodo code) is intended to be executed under an MPI Single Program Multiple Data ([SPMD](https://en.wikipedia.org/wiki/SPMD)) paradigm, where MPI processes are launched in the beginning and all run the same code.\n",
    "\n",
    "\n",
    "For example, we can save an example code in a file and use *mpiexec* to launch 4 processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=[\"df\"])\n",
    "def f(n, a):\n",
    "    df = pd.DataFrame({'A': np.arange(n) + a})\n",
    "    return df\n",
    "\n",
    "print(f(8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%save -f test_bodo.py 2 # cell number of previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 4 python test_bodo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `mpiexec` launches 4 Python processes, each of which executes the same `test_bodo.py` file.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b>\n",
    "\n",
    "- Python codes outside of Bodo functions execute sequentially on every process.\n",
    "- Bodo functions run in parallel assuming that Bodo is able to parallelize them. Otherwise, they also run sequentially on every process. Bodo warns if it does not find parallelism (more details later).\n",
    "\n",
    "</div>\n",
    "\n",
    "Note how the prints, which are regular Python code executed outside of Bodo, run for each process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Jupyter notebook, parallel execution happens in very much the same way. We start a set of MPI engines through `ipyparallel` and activate a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client(profile='mpi')\n",
    "view = c[:]\n",
    "view.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this initialization, any code that we run in the notebook with `%%px --block` is sent for execution on all MPI engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def f(n):\n",
    "    df = pd.DataFrame({'A': np.arange(n)})\n",
    "    return df\n",
    "\n",
    "print(f(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel APIs\n",
    "\n",
    "Bodo provides a limited number of parallel APIs to support advanced cases that may need them. Example below demonstrates getting the process number from Bodo (called `rank` in MPI terminology), getting total number of processes, and synchronizing all processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "# some work on only rank 0\n",
    "if bodo.get_rank() == 0:\n",
    "    print(\"rank 0 done\")\n",
    "\n",
    "\n",
    "print(\"rank \"+ str(bodo.get_rank()) + \" here\")\n",
    "print(\"total ranks:\", bodo.get_size())\n",
    "\n",
    "# make sure all processes are synchronized\n",
    "# (e.g. all processes need to see effect of rank 0's work)\n",
    "bodo.barrier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> As in this example, it is possible to have each process follow a different control flow, but all processes must always call the same Bodo functions in the same order.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Distribution\n",
    "\n",
    "Bodo parallelize computation by dividing data into separate chunks across processes. However, some data handled by a Bodo function may not be divided into chunks. There are are two main data distribution schemes:\n",
    "\n",
    "- Replicated (*REP*): the data associated with the variable is the same on every process.\n",
    "- One-dimensional (*1D*): the data is divided into chunks, split along one dimension (rows of a dataframe or first dimension of an array)\n",
    "\n",
    "Bodo finds distribution of variables automatically, using the nature of the computation that produces them. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    m = df[[\"power\", \"speed\"]].mean()\n",
    "    return m\n",
    "\n",
    "res = mean_power_speed()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `df` is parallelized but `m` is replicated, even though it is a Series. Semantically, it makes sense for output of `mean` operation to be replicated on all processors, since it is a reduction and produces \"small\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Diagnostics\n",
    "\n",
    "The distributions found by Bodo can be printed either by setting `BODO_DISTRIBUTED_DIAGNOSTICS=1` or calling `distributed_diagnostics()` on the compiled function. Let's examine the previous example's distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "mean_power_speed.distributed_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are renamed due to optimization. The output shows that `power` and `speed` columns of `df` are distributed (`1D_Block`) but `m` is replicated (`REP`). This is because `df` is output of `read_parquet` and input of `mean`, both of which can be distributed. `m` is output of `mean`, which is always replicated (available on every process)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Arguments and Return Values\n",
    "\n",
    "Now let's see what happens if we pass the data into the Bodo function as a function parameter but don't mark it as distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed(df):\n",
    "    m = df[[\"power\", \"speed\"]].mean()\n",
    "    return m\n",
    "\n",
    "df = pd.read_parquet('cycling_dataset.pq')\n",
    "res = mean_power_speed(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program runs and returns the same correct value as before, but everything is replicated on all processes and *there is no parallelism!* Bodo's warning indicates this explicitly. Therefore, each process reads the whole data file and calculates the mean of the dataframe independently.\n",
    "\n",
    "This is because data is passed to Bodo as argument without setting the distributed flag, and Bodo assumes correctly that the data is replicated. Bodo then follows dependencies and replicates the whole program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, return values will be replicated by default, since data is passed to regular Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return df\n",
    "\n",
    "df = mean_power_speed()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> Bodo assumes that input parameters and return values are replicated, unless if specified using `distributed` flag. This can lead to replication of the whole program due to dependencies.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Distributed Data to Bodo\n",
    "\n",
    "Bodo functions may require distributed arguments and return values in some cases such as passing distributed data across Bodo functions. This can be achieved using the `distributed` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def read_data():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    print(\"total size\", len(df))\n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def mean_power(df):\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "df = read_data()\n",
    "# df is a chunk of data on each process\n",
    "print(\"chunk size\", len(df))\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scattering Data\n",
    "\n",
    "One can distribute data manually by *scattering* data from one process to all processes. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def mean_power(df):\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "df = None\n",
    "# only rank 0 reads the data\n",
    "if bodo.get_rank() == 0:\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "\n",
    "df = bodo.scatterv(df)\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data\n",
    "\n",
    "One can *gather* distributed data into a single process manually. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return bodo.gatherv(df)\n",
    "\n",
    "df = mean_power()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, distributed data can be gathered and sent to all processes, effectively replicating the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return bodo.allgatherv(df)\n",
    "\n",
    "df = mean_power()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parallel I/O\n",
    "<img style=\"float: right;\" src=\"img/file-read.jpg\">\n",
    "\n",
    "Efficient parallel data processing requires data I/O to be parallelized effectively as well. Bodo provides parallel file I/O for many different formats such as [Parquet](http://parquet.apache.org),\n",
    "CSV, JSON, Numpy binaries, [HDF5](http://www.h5py.org) and SQL databases. This diagram demonstrates how chunks of data are partitioned among parallel execution engines by Bodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet\n",
    "\n",
    "Parquet is a commonly used file format in analytics due to its efficient columnar storage. Bodo supports the standard pandas API for reading Parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "from IPython.display import display\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def pq_read():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return df\n",
    "\n",
    "# on each process, this returns the data chunk read by that process\n",
    "res = pq_read()\n",
    "if bodo.get_rank() == 0:\n",
    "    display(res.head())  # display results of first process only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo also supports the pandas API for writing Parquet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def generate_data_and_write():\n",
    "    df = pd.DataFrame({\"A\": np.arange(80)})\n",
    "    df.to_parquet(\"pq_output.pq\")\n",
    "\n",
    "generate_data_and_write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"\n",
    "<b>Note:</b> Bodo writes a directory of parquet files (one file per process) when writing distributed data. Bodo writes a single file when the data is replicated.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `df` is distributed data so it is written to a directory a parquet files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo supports parallel read of single Parquet files, as well as directory of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def read_parquet_dir():\n",
    "    df = pd.read_parquet(\"pq_output.pq\")\n",
    "    return df\n",
    "\n",
    "df = read_parquet_dir()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV\n",
    "CSV is a common text format for data exchange. Bodo supports the standard pandas API to read CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def csv_example():\n",
    "    df = pd.read_csv('cycling_dataset.csv')\n",
    "    return df\n",
    "\n",
    "res = csv_example()\n",
    "if bodo.get_rank() == 0:\n",
    "    display(res.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the pandas `read_csv()` functionality, Bodo can also read a directory containing multiple CSV files (all part of the same dataframe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"\n",
    "<b>Note:</b>\n",
    "\n",
    "When writing distributed data to CSV:\n",
    "- To S3 or HDFS: Bodo writes to a directory of CSV files (one file per process)\n",
    "- To POSIX filesystem (e.g. local filesystem on Linux): Bodo writes the distributed data in parallel to a single file.\n",
    "\n",
    "If the data is replicated, Bodo always writes to a single file.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5\n",
    "HDF5 is a common format in scientific computing, especially for multi-dimensional numerical data. HDF5 can be very efficient at scale, since it has native parallel I/O support. Bodo supports the standard h5py APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import h5py\n",
    "\n",
    "@bodo.jit\n",
    "def example_h5():\n",
    "    f = h5py.File(\"data.h5\", \"r\")\n",
    "    return f['A'][:].sum()\n",
    "\n",
    "res = example_h5()\n",
    "if bodo.get_rank() == 0: print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Binary Files\n",
    "Bodo supports reading and writing binary files using Numpy APIs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def example_np_io():\n",
    "    A = np.fromfile(\"data.dat\", np.int64)\n",
    "    return A.sum()\n",
    "\n",
    "res = example_np_io()\n",
    "if bodo.get_rank() == 0: print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Annotation (when file name is unknown at compile time)\n",
    "\n",
    "Bodo needs to know or infer the types for all data, but this is not always possible for input from files if file name is not known at compilation time.\n",
    "\n",
    "For example, suppose we have the following files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_files(n):\n",
    "    for i in range(n):\n",
    "        df = pd.DataFrame({\"A\": np.arange(5, dtype=np.int64)})\n",
    "        df.to_parquet(\"test\" + str(i) + \".pq\")\n",
    "\n",
    "generate_files(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we want to read them like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def read_data(n):\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"test\" + str(i) + \".pq\"\n",
    "        df = pd.read_parquet(file_name)\n",
    "        print(df)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "result = read_data(5)\n",
    "# BodoError: Parquet schema not available. Either path argument should be\n",
    "# constant for Bodo to look at the file at compile time or schema should be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file names are computed at runtime, which doesn't allow the compiler to find the files and extract the schemas. As shown below, the solution is to use *type annotation* to provide data types to the compiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type annotation for Parquet files\n",
    "\n",
    "Example below uses the `locals` option of the decorator to provide the compiler with the schema of the local variable `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(locals={\"df\": {\"A\": bodo.int64[:]}})\n",
    "def read_data(n):\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"test\" + str(i) + \".pq\"\n",
    "        df = pd.read_parquet(file_name)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "result = read_data(5)\n",
    "if bodo.get_rank() == 0:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type annotation for CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CSV files, we can annotate types in the same way as pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "def generate_files(n):\n",
    "    for i in range(n):\n",
    "        df = pd.DataFrame({\"A\": np.arange(5, dtype=np.int64)})\n",
    "        df.to_csv(\"test\" + str(i) + \".csv\", index=False)\n",
    "\n",
    "@bodo.jit\n",
    "def read_data(n):\n",
    "    coltypes = {'A': np.int64}\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"test\" + str(i) + \".csv\"\n",
    "        df = pd.read_csv(file_name, names=coltypes.keys(), dtype=coltypes, header=True)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "n = 5\n",
    "if bodo.get_rank() == 0:\n",
    "    generate_files(n)\n",
    "bodo.barrier()\n",
    "result = read_data(n)\n",
    "if bodo.get_rank() == 0:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Advanced Features\n",
    "\n",
    "## Explicit Parallel Loops\n",
    "Sometimes explicit parallel loops are required since a program cannot be written in terms of data-parallel operators easily. In this case, one can use Bodo’s `prange` in place of `range` to specify that a loop can be parallelized. The user is required to make sure the loop does not have cross iteration dependencies except for supported reductions.\n",
    "\n",
    "The example below demonstrates a parallel loop with a reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import bodo\n",
    "from bodo import prange\n",
    "import numpy as np\n",
    "\n",
    "@bodo.jit\n",
    "def prange_test(n):\n",
    "    A = np.random.ranf(n)\n",
    "    s = 0\n",
    "    for i in prange(len(A)):\n",
    "        bodo.parallel_print(\"rank\", bodo.get_rank())\n",
    "        # A[i]: distributed data access with loop index\n",
    "        # s: a supported sum reduction\n",
    "        s += A[i]\n",
    "    return s\n",
    "\n",
    "res = prange_test(10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, reductions using +=, *=, min, and max operators are supported. Iterations are simply divided between processes and executed in parallel, but reductions are handled using data exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with non-Bodo APIs\n",
    "There are multiple methods for integration with APIs that Bodo does not support natively:\n",
    "1. Switch to python object mode inside jit functions\n",
    "2. Pass data in and out of jit functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object mode\n",
    "Object mode allows switching to a python intepreted context to be able to run non-jittable code. The main requirement is specifying the type of returned values. For example, the following code calls a Scipy function on data elements of a distributed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import scipy.special as sc\n",
    "\n",
    "@bodo.jit\n",
    "def objmode_test(n):\n",
    "    A = np.random.ranf(n)\n",
    "    s = 0\n",
    "    for i in prange(len(A)):\n",
    "        x = A[i]\n",
    "        with bodo.objmode(y=\"float64\"):\n",
    "            y = sc.entr(x)  # call entropy function on each data element\n",
    "        s += y\n",
    "    return s\n",
    "\n",
    "res = objmode_test(10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Numba's documentation for [objmode](http://numba.pydata.org/numba-doc/latest/user/withobjmode.html#the-objmode-context-manager) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Distributed Data\n",
    "Bodo can receive or return chunks of distributed data to allow flexible integration with any non-Bodo Python code. The following example passes chunks of data to interpolate with Scipy, and returns interpolation results back to jit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import scipy.interpolate\n",
    "\n",
    "@bodo.jit(distributed=[\"X\", \"Y\", \"X2\"])\n",
    "def dist_pass_test(n):\n",
    "    X = np.arange(n)\n",
    "    Y = np.exp(-X/3.0)\n",
    "    X2 = np.arange(0, n, 0.5)\n",
    "    return X, Y, X2\n",
    "\n",
    "X, Y, X2 = dist_pass_test(100)\n",
    "# clip potential out-of-range values\n",
    "X2 = np.minimum(np.maximum(X2, X[0]), X[-1])\n",
    "f = scipy.interpolate.interp1d(X, Y)\n",
    "Y2 = f(X2)\n",
    "\n",
    "@bodo.jit(distributed={'Y2'})\n",
    "def dist_pass_res(Y2):\n",
    "    return Y2.sum()\n",
    "\n",
    "res = dist_pass_res(Y2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "A simple approach for visualization is pulling data to the notebook process from execution engines and using Python visualization libraries. Distributed data can be gathered if there is enough memory on the local machine. Otherwise, a sample of data can be gathered. The example code below demonstrates gathering a portion of data for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def dist_gather_test(n):\n",
    "    X = np.arange(n)\n",
    "    Y = np.exp(-X/3.0)\n",
    "    return bodo.gatherv(Y[::10])  # gather every 10th element\n",
    "\n",
    "\n",
    "Y_sample = dist_gather_test(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "Y_sample = view['Y_sample'][0]\n",
    "plt.plot(Y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Troubleshooting\n",
    "\n",
    "## Compilation Tips\n",
    "\n",
    "The general recommendation is to **compile the code that is performance critical and/or requires scaling**.\n",
    "\n",
    "1. Don’t use Bodo for scripts that set up infrastucture or do initializations.\n",
    "2. Only use Bodo for data processing and analytics code.\n",
    "\n",
    "This reduces the risk of hitting unsupported features and reduces compilation time. To do so, simply factor out the code that needs to be compiled by Bodo and pass data into Bodo compiled functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation Errors\n",
    "\n",
    "The most common reason is that the code relies on features that Bodo currently does not support, so it’s important to understand the limitations of Bodo. There are 4 main limitations:\n",
    "\n",
    "1. Not supported Pandas API (see [here](http://docs.bodo.ai/latest/source/pandas.html#pandas))\n",
    "2. Not supported NumPy API (see [here](http://docs.bodo.ai/latest/source/numpy.html#numpy))\n",
    "3. Not supported Python features or datatypes (see [here](http://docs.bodo.ai/latest/source/not_supported.html#unsupported-python-constructs))\n",
    "4. Not supported Python programs due to type instability\n",
    "\n",
    "Solutions:\n",
    "\n",
    "1. Make sure your code works in Python (using a small sample dataset): a lot of the times a Bodo decorated function doesn’t compile, but it does not compile in Python either.\n",
    "2. Replace unsupported operations with supported operations if possible.\n",
    "3. Refactor the code to partially use regular Python, explained in \"Integration with non-Bodo APIs\" section.\n",
    "\n",
    "For example, the code below uses heterogenous list values inside `a` which cannot be typed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f(n):\n",
    "    a = [[-1, \"a\"]]\n",
    "    for i in range(n):\n",
    "        a.append([i, \"a\"])\n",
    "    return a\n",
    "\n",
    "print(f(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this use case can be rewritten to use tuple values instead of lists since values don't change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f(n):\n",
    "    a = [(-1, \"a\")]\n",
    "    for i in range(n):\n",
    "        a.append((i, \"a\"))\n",
    "    return a\n",
    "\n",
    "print(f(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Schema Stability\n",
    "\n",
    "Deterministic dataframe schemas (column names and types), which are required in most data systems, are key for type stability. For example, variable `df` in example below could be either a single column dataframe or a two column one – Bodo cannot determine it at compilation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f(a):\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    df2 = pd.DataFrame({\"A\": [1, 3, 4], \"C\": [-1, -2, -3]})\n",
    "    if len(a) > 3:\n",
    "        df = df.merge(df2)\n",
    "\n",
    "    return df.mean()\n",
    "\n",
    "print(f([2, 3]))\n",
    "# TypeError: Cannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), False)\n",
    "# and dataframe((array(int64, 1d, C), array(int64, 1d, C)), RangeIndexType(none), ('A', 'C'), False) for 'df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message means that Bodo cannot find a type that can unify the two types into a single type. This code can be refactored so that the if control flow is executed in regular Python context, but the rest of computation is in Bodo functions. For example, one could use two versions of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f1():\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    return df.mean()\n",
    "\n",
    "@bodo.jit\n",
    "def f2():\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    df2 = pd.DataFrame({\"A\": [1, 3, 4], \"C\": [-1, -2, -3]})\n",
    "    df = df.merge(df2)\n",
    "    return df.mean()\n",
    "\n",
    "a = [2, 3]\n",
    "if len(a) > 3:\n",
    "    print(f1())\n",
    "else:\n",
    "    print(f2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common place where schema stability may be compromised is in passing non-constant list of key column names to dataframe operations such as `groupby`, `merge` and `sort_values`. In these operations, Bodo should be able to deduce the list of key column names at compile time in order to determine the output dataframe schema. For example, the program below is potentially type unstable since Bodo may not be able to infer `column_list` during compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f(a):\n",
    "    column_list = a[0]  # some computation that cannot be inferred statically\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n",
    "    return df.groupby(column_list).sum()\n",
    "\n",
    "f([\"A\"])\n",
    "# BodoError: groupby(): 'by' parameter only supports a constant column label or column labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nullable Integers in Pandas\n",
    "\n",
    "DataFrame and Series objects with integer data need special care due to [integer NA issues in Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#nan-integer-na-values-and-na-type-promotions). By default, Pandas dynamically converts integer columns to floating point when missing values (NAs) are needed, which can result in loss of precision as well as type instability.\n",
    "\n",
    "Pandas introduced [a new nullable integer data type](https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html#integer-na) that can solve this issue, which is also supported by Bodo. For example, this code reads column A into a nullable integer array (the capital “I” denotes nullable integer type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    \"11,1.2\\n\"\n",
    "    \"-2,\\n\"\n",
    "    \",3.1\\n\"\n",
    "    \"4,-0.1\\n\"\n",
    ")\n",
    "\n",
    "with open(\"data.csv\", \"w\") as f:\n",
    "    f.write(data)\n",
    "\n",
    "\n",
    "@bodo.jit(distributed=[\"df\"])\n",
    "def f():\n",
    "    dtype = {\"A\": \"Int64\", \"B\": \"float64\"}\n",
    "    df = pd.read_csv(\"data.csv\", dtype = dtype, names = dtype.keys())\n",
    "    return df\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxing/Unboxing Overheads\n",
    "\n",
    "Bodo uses efficient native data structures which can be different than Python. When Python values are passed to Bodo, they are *unboxed* to native representation. On the other hand, returning Bodo values requires *boxing* to Python objects. Boxing and unboxing can have significant overhead depending on size and type of data. For example, passing string column between Python/Bodo repeatedly can be expensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit(distributed=[\"df\"])\n",
    "def gen_data():\n",
    "    df = pd.read_parquet(\"cycling_dataset.pq\")\n",
    "    df[\"hr\"] = df[\"hr\"].astype(str)\n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=[\"df\", \"x\"])\n",
    "def mean_power(df):\n",
    "    x = df.hr.str[1:]\n",
    "    return x\n",
    "\n",
    "df = gen_data()\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can try to keep data in Bodo functions as much as possible to avoid boxing/unboxing overheads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit(distributed=[\"df\"])\n",
    "def gen_data():\n",
    "    df = pd.read_parquet(\"cycling_dataset.pq\")\n",
    "    df[\"hr\"] = df[\"hr\"].astype(str)\n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=[\"df\", \"x\"])\n",
    "def mean_power(df):\n",
    "    x = df.hr.str[1:]\n",
    "    return x\n",
    "\n",
    "@bodo.jit\n",
    "def f():\n",
    "    df = gen_data()\n",
    "    res = mean_power(df)\n",
    "    print(res)\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
