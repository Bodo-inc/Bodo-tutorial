{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo Extended Tutorial\n",
    "\n",
    "This is a continuation of the \"Getting Started\" tutorial. You are encouraged to visit that tutorial first if you have not done so already. In this tutorial, we will explain core Bodo concepts in more detail, introduce additional Bodo features, and discuss more advanced topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Please follow the [Bodo installation](http://docs.bodo.ai/latest/source/install.html) and [Jupyter Notebook Setup](http://docs.bodo.ai/latest/source/jupyter.html) pages to setup the environment. Also, make sure MPI engines are started in the `IPython Clusters` tab (or using `ipcluster start -n 4 --profile=mpi` in command line)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bodo Basics\n",
    "\n",
    "### JIT (Just-in-time) Compilation Workflow\n",
    "\n",
    "Bodo provides a just-in-time (JIT) compilation workflow using the `@bodo.jit` decorator, which replaces a Python function with a so-called `Dispatcher` object. Bodo compiles the function the first time a Dispatcher object is called and reuses the compiled version afterwards. The function is recompiled only if the same function is called with different argument types (not often in practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUDispatcher(<function f at 0x1204ab160>)\n",
      "   A\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "   A\n",
      "0  2\n",
      "1  3\n",
      "2  4\n",
      "     A\n",
      "0  2.2\n",
      "1  3.2\n",
      "2  4.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def f(n, a):\n",
    "    df = pd.DataFrame({'A': np.arange(n) + a})\n",
    "    return df.head(3)\n",
    "\n",
    "print(f)\n",
    "print(f(8, 1))  # compiles for (int, int) input types\n",
    "print(f(8, 2))  # same input types, no need to compile\n",
    "print(f(8, 2.2))  # compiles for (int, float) input types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this is completely transparent to the caller, and does not affect any Python code calling the function.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"\n",
    "<b>Note:</b>\n",
    "In many cases, the binary that Bodo generates when compiling a function can be saved to disk to be reused across program executions. See \"Bodo Caching\" below for more information.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Execution Model\n",
    "\n",
    "As we saw in the \"Getting Started\" tutorial, Bodo transforms functions for parallel execution. However, the dispatcher does not launch processes or threads on the fly. Instead, the Python application (including non-Bodo code) is intended to be executed under an MPI Single Program Multiple Data ([SPMD](https://en.wikipedia.org/wiki/SPMD)) paradigm, where MPI processes are launched in the beginning and all run the same code.\n",
    "\n",
    "\n",
    "For example, we can save an example code in a file and use *mpiexec* to launch 4 processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=[\"df\"])\n",
    "def f(n, a):\n",
    "    df = pd.DataFrame({'A': np.arange(n) + a})\n",
    "    return df\n",
    "\n",
    "print(f(8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%save -f test_bodo.py 2 # cell number of previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A\r\n",
      "2  3\r\n",
      "3  4\r\n",
      "   A\r\n",
      "4  5\r\n",
      "5  6\r\n",
      "   A\r\n",
      "0  1\r\n",
      "1  2\r\n",
      "   A\r\n",
      "6  7\r\n",
      "7  8\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 4 python test_bodo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `mpiexec` launches 4 Python processes, each of which executes the same `test_bodo.py` file.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"\n",
    "<b>Important:</b>\n",
    "\n",
    "- Python codes outside of Bodo functions execute sequentially on every process.\n",
    "- Bodo functions run in parallel assuming that Bodo is able to parallelize them. Otherwise, they also run sequentially on every process. Bodo warns if it does not find parallelism (more details later).\n",
    "\n",
    "</div>\n",
    "\n",
    "Note how the prints, which are regular Python code executed outside of Bodo, run for each process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Jupyter notebook, parallel execution happens in very much the same way. We start a set of MPI engines through `ipyparallel` and activate a client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client(profile='mpi')\n",
    "view = c[:]\n",
    "view.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this initialization, any code that we run in the notebook with `%%px --block` is sent for execution on all MPI engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "   A\n",
      "0  0\n",
      "1  1\n",
      "[stdout:1] \n",
      "   A\n",
      "2  2\n",
      "3  3\n",
      "[stdout:2] \n",
      "   A\n",
      "4  4\n",
      "5  5\n",
      "[stdout:3] \n",
      "   A\n",
      "6  6\n",
      "7  7\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def f(n):\n",
    "    df = pd.DataFrame({'A': np.arange(n)})\n",
    "    return df\n",
    "\n",
    "print(f(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel APIs\n",
    "\n",
    "Bodo provides a limited number of parallel APIs to support advanced cases that may need them. The example below demonstrates getting the process number from Bodo (called `rank` in MPI terminology), getting total number of processes, and synchronizing all processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "rank 0 done\n",
      "rank 0 here\n",
      "total ranks: 4\n",
      "[stdout:1] \n",
      "rank 1 here\n",
      "total ranks: 4\n",
      "[stdout:2] \n",
      "rank 2 here\n",
      "total ranks: 4\n",
      "[stdout:3] \n",
      "rank 3 here\n",
      "total ranks: 4\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "# some work only on rank 0\n",
    "if bodo.get_rank() == 0:\n",
    "    print(\"rank 0 done\")\n",
    "\n",
    "\n",
    "print(\"rank\", bodo.get_rank(), \"here\")\n",
    "print(\"total ranks:\", bodo.get_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common pattern is using barriers to make sure all processes see side-effects at the same time. For example, a process can delete files from storage while others wait before writing to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import shutil, os\n",
    "import numpy as np\n",
    "\n",
    "# remove file if exists\n",
    "if bodo.get_rank() == 0:\n",
    "    if os.path.exists(\"data.pq\"):\n",
    "        shutil.rmtree(\"data.pq\")\n",
    "\n",
    "# make sure all processes are synchronized\n",
    "# (e.g. all processes need to see effect of rank 0's work)\n",
    "bodo.barrier()\n",
    "\n",
    "@bodo.jit\n",
    "def f(n):\n",
    "    df = pd.DataFrame({\"A\": np.arange(n)})\n",
    "    df.to_parquet(\"data.pq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> As in this example, it is possible to have each process follow a different control flow, but all processes must always call the same Bodo functions in the same order.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution\n",
    "\n",
    "Bodo parallelizes computation by dividing data into separate chunks across processes. However, some data handled by a Bodo function may not be divided into chunks. There are are two main data distribution schemes:\n",
    "\n",
    "- Replicated (*REP*): the data associated with the variable is the same on every process.\n",
    "- One-dimensional (*1D*): the data is divided into chunks, split along one dimension (rows of a dataframe or first dimension of an array).\n",
    "\n",
    "Bodo determines distribution of variables automatically, using the nature of the computation that produces them. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:1] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:2] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:3] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    m = df[[\"power\", \"speed\"]].mean()\n",
    "    return m\n",
    "\n",
    "res = mean_power_speed()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `df` is parallelized (each process reads a different chunk) but `m` is replicated, even though it is a Series. Semantically, it makes sense for the output of `mean` operation to be replicated on all processors, since it is a reduction and produces \"small\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Diagnostics\n",
    "\n",
    "The distributions found by Bodo can be printed either by setting the environment variable `BODO_DISTRIBUTED_DIAGNOSTICS=1` or calling `distributed_diagnostics()` on the compiled function. Let's examine the previous example's distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Distributed diagnostics for function mean_power_speed, <ipython-input-15-b6752a146201> (1)\n",
      "\n",
      "Data distributions:\n",
      "   power.5929                1D_Block\n",
      "   speed.5930                1D_Block\n",
      "   $A.6145.6484              1D_Block\n",
      "   $A.6208.6494              1D_Block\n",
      "   $data.6117.6505           REP\n",
      "   $12call_method.5.6468     REP\n",
      "   $66call_method.31.6135    REP\n",
      "   $m.6507                   REP\n",
      "   $30return_value.12        REP\n",
      "\n",
      "Parfor distributions:\n",
      "   20                   1D_Block\n",
      "   21                   1D_Block\n",
      "\n",
      "Distributed listing for function mean_power_speed, <ipython-input-15-b6752a146201> (1)\n",
      "--------------------------------------------------| parfor_id/variable: distribution\n",
      "@bodo.jit                                         | \n",
      "def mean_power_speed():                           | \n",
      "    df = pd.read_parquet('cycling_dataset.pq')----| power.5929: 1D_Block, speed.5930: 1D_Block\n",
      "    m = df[[\"power\", \"speed\"]].mean()-------------| $A.6145.6484: 1D_Block, $A.6208.6494: 1D_Block\n",
      "    return m--------------------------------------| $30return_value.12: REP\n",
      "\n",
      "Distributed analysis set $data.6117.6505 as replicated due to call to function 'np.asarray' (unsupported function or usage)\n",
      "Distributed analysis set $12call_method.5.6468 as replicated due to call to function 'bodo.libs.str_arr_ext.str_arr_from_sequence' (unsupported function or usage)\n",
      "Distributed analysis replicated output variable $30return_value.12. Set distributed flag for the original variable if distributed partitions should be returned.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "mean_power_speed.distributed_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are renamed due to optimization. The output shows that `power` and `speed` columns of `df` are distributed (`1D_Block`) but `m` is replicated (`REP`). This is because `df` is output of `read_parquet` and input of `mean`, both of which can be distributed by Bodo. `m` is output of `mean`, which is always replicated (available on every process)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Arguments and Return Values\n",
    "\n",
    "Now let's see what happens if we pass the data into the Bodo function as a function parameter but don't mark it as distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:1] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:2] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:3] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "/bodo/bodo/transforms/distributed_analysis.py:229: BodoWarning: No parallelism found for function 'mean_power_speed'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed(df):\n",
    "    m = df[[\"power\", \"speed\"]].mean()\n",
    "    return m\n",
    "\n",
    "df = pd.read_parquet('cycling_dataset.pq')\n",
    "res = mean_power_speed(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program runs and returns the same correct value as before, but everything is replicated on all processes and *there is no parallelism!* Bodo's warning indicates this explicitly. Therefore, each process reads the whole data file and calculates the mean of the dataframe independently.\n",
    "\n",
    "This is because data is passed to Bodo as argument without setting the `distributed` flag, and Bodo assumes correctly that the data is replicated (note that the dataframe in this case is read using pandas). Bodo then follows dependencies and replicates the whole program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, return values will be replicated by default, since data is passed to regular Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:1] \n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:2] \n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:3] \n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "/Users/ehsan/dev/bodo/bodo/transforms/distributed_analysis.py:229: BodoWarning: No parallelism found for function 'mean_power_speed'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import bodo\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 7\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return df\n",
    "\n",
    "df = mean_power_speed()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"\n",
    "<b>Important:</b> Bodo assumes that input parameters and return values are replicated, unless if specified using `distributed` flag. This can lead to replication of the whole program due to dependencies.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Distributed Data to Bodo\n",
    "\n",
    "Bodo functions may require distributed arguments and return values in some cases such as passing distributed data across Bodo functions. This can be achieved using the `distributed` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "total size 3902\n",
      "chunk size 976\n",
      "102.07842132239877\n",
      "[stdout:1] \n",
      "chunk size 976\n",
      "102.07842132239877\n",
      "[stdout:2] \n",
      "chunk size 975\n",
      "102.07842132239877\n",
      "[stdout:3] \n",
      "chunk size 975\n",
      "102.07842132239877\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def read_data():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    print(\"total size\", len(df))\n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def mean_power(df):\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "df = read_data()\n",
    "# df is a chunk of data on each process\n",
    "print(\"chunk size\", len(df))\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scattering Data\n",
    "\n",
    "One can distribute data manually by *scattering* data from one process to all processes. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 102.07842132239877\n",
      "[stdout:1] 102.07842132239877\n",
      "[stdout:2] 102.07842132239877\n",
      "[stdout:3] 102.07842132239877\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def mean_power(df):\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "df = None\n",
    "# only rank 0 reads the data\n",
    "if bodo.get_rank() == 0:\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "\n",
    "df = bodo.scatterv(df)\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data\n",
    "\n",
    "One can *gather* distributed data into a single process manually. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:1] \n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, altitude, cadence, distance, hr, latitude, longitude, power, speed, time]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 10 columns]\n",
      "[stdout:2] \n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, altitude, cadence, distance, hr, latitude, longitude, power, speed, time]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 10 columns]\n",
      "[stdout:3] \n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, altitude, cadence, distance, hr, latitude, longitude, power, speed, time]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return bodo.gatherv(df)\n",
    "\n",
    "df = mean_power()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, distributed data can be gathered and sent to all processes, effectively replicating the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:1] \n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:2] \n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:3] \n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return bodo.allgatherv(df)\n",
    "\n",
    "df = mean_power()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel I/O\n",
    "\n",
    "![Bodo reads file chunks in parallel](img/file-read.jpg)\n",
    "\n",
    "Efficient parallel data processing requires data I/O to be parallelized effectively as well. Bodo provides parallel file I/O for many different formats such as [Parquet](http://parquet.apache.org),\n",
    "CSV, JSON, Numpy binaries, [HDF5](http://www.h5py.org) and SQL databases. This diagram demonstrates how chunks of data are partitioned among parallel execution engines by Bodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet\n",
    "\n",
    "Parquet is a commonly used file format in analytics due to its efficient columnar storage. Bodo supports the standard pandas API for reading Parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "     Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0             0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1             1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2             2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3             3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4             4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "..          ...         ...      ...  ...    ...    ...                 ...\n",
      "971         971  132.399994        0  ...      1  4.385 2016-10-20 22:20:32\n",
      "972         972  132.199997        0  ...      1  4.122 2016-10-20 22:20:33\n",
      "973         973  132.199997        0  ...    283  4.715 2016-10-20 22:20:34\n",
      "974         974  132.399994       70  ...     98  5.161 2016-10-20 22:20:35\n",
      "975         975  132.399994      115  ...      1  5.155 2016-10-20 22:20:36\n",
      "\n",
      "[976 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def pq_read():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return df\n",
    "\n",
    "# on each process, this returns the data chunk read by that process\n",
    "res = pq_read()\n",
    "if bodo.get_rank() == 0:\n",
    "    print(res)  # display results of first process only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo also supports the pandas API for writing Parquet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def generate_data_and_write():\n",
    "    df = pd.DataFrame({\"A\": np.arange(80)})\n",
    "    df.to_parquet(\"pq_output.pq\")\n",
    "\n",
    "generate_data_and_write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"\n",
    "<b>Note:</b> Bodo writes a directory of parquet files (one file per process) when writing distributed data. Bodo writes a single file when the data is replicated.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `df` is distributed data so it is written to a directory a parquet files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo supports parallel read of single Parquet files, as well as directory of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "     A\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "6    6\n",
      "7    7\n",
      "8    8\n",
      "9    9\n",
      "10  10\n",
      "11  11\n",
      "12  12\n",
      "13  13\n",
      "14  14\n",
      "15  15\n",
      "16  16\n",
      "17  17\n",
      "18  18\n",
      "19  19\n",
      "[stdout:1] \n",
      "     A\n",
      "20  20\n",
      "21  21\n",
      "22  22\n",
      "23  23\n",
      "24  24\n",
      "25  25\n",
      "26  26\n",
      "27  27\n",
      "28  28\n",
      "29  29\n",
      "30  30\n",
      "31  31\n",
      "32  32\n",
      "33  33\n",
      "34  34\n",
      "35  35\n",
      "36  36\n",
      "37  37\n",
      "38  38\n",
      "39  39\n",
      "[stdout:2] \n",
      "     A\n",
      "40  40\n",
      "41  41\n",
      "42  42\n",
      "43  43\n",
      "44  44\n",
      "45  45\n",
      "46  46\n",
      "47  47\n",
      "48  48\n",
      "49  49\n",
      "50  50\n",
      "51  51\n",
      "52  52\n",
      "53  53\n",
      "54  54\n",
      "55  55\n",
      "56  56\n",
      "57  57\n",
      "58  58\n",
      "59  59\n",
      "[stdout:3] \n",
      "     A\n",
      "60  60\n",
      "61  61\n",
      "62  62\n",
      "63  63\n",
      "64  64\n",
      "65  65\n",
      "66  66\n",
      "67  67\n",
      "68  68\n",
      "69  69\n",
      "70  70\n",
      "71  71\n",
      "72  72\n",
      "73  73\n",
      "74  74\n",
      "75  75\n",
      "76  76\n",
      "77  77\n",
      "78  78\n",
      "79  79\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def read_parquet_dir():\n",
    "    df = pd.read_parquet(\"pq_output.pq\")\n",
    "    return df\n",
    "\n",
    "df = read_parquet_dir()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "CSV is a common text format for data exchange. Bodo supports the standard pandas API to read CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "       0    1           2  ...    8      9                   10\n",
      "0      0    0  185.800003  ...   45  3.459  2016-10-20 22:01:26\n",
      "1      1    1  185.800003  ...    0  3.710  2016-10-20 22:01:27\n",
      "2      2    2  186.399994  ...   42  3.874  2016-10-20 22:01:28\n",
      "3      3    3  186.800003  ...    5  4.135  2016-10-20 22:01:29\n",
      "4      4    4  186.600006  ...    1  4.250  2016-10-20 22:01:30\n",
      "..   ...  ...         ...  ...  ...    ...                  ...\n",
      "971  971  971  132.399994  ...    1  4.385  2016-10-20 22:20:32\n",
      "972  972  972  132.199997  ...    1  4.122  2016-10-20 22:20:33\n",
      "973  973  973  132.199997  ...  283  4.715  2016-10-20 22:20:34\n",
      "974  974  974  132.399994  ...   98  5.161  2016-10-20 22:20:35\n",
      "975  975  975  132.399994  ...    1  5.155  2016-10-20 22:20:36\n",
      "\n",
      "[976 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def csv_example():\n",
    "    df = pd.read_csv('cycling_dataset.csv', header=None)\n",
    "    return df\n",
    "\n",
    "res = csv_example()\n",
    "if bodo.get_rank() == 0:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the pandas `read_csv()` functionality, Bodo can also read a directory containing multiple CSV files (all part of the same dataframe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"\n",
    "<b>Note:</b>\n",
    "\n",
    "When writing distributed data to CSV:\n",
    "\n",
    "- To S3 or HDFS: Bodo writes to a directory of CSV files (one file per process)\n",
    "- To POSIX filesystem (e.g. local filesystem on Linux): Bodo writes the distributed data in parallel to a single file.\n",
    "\n",
    "If the data is replicated, Bodo always writes to a single file.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5\n",
    "HDF5 is a common format in scientific computing, especially for multi-dimensional numerical data. HDF5 can be very efficient at scale, since it has native parallel I/O support. Bodo supports the standard h5py APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 66\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import h5py\n",
    "\n",
    "@bodo.jit\n",
    "def example_h5():\n",
    "    f = h5py.File(\"data.h5\", \"r\")\n",
    "    return f['A'][:].sum()\n",
    "\n",
    "res = example_h5()\n",
    "if bodo.get_rank() == 0: print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Binary Files\n",
    "Bodo supports reading and writing binary files using Numpy APIs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 45\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def example_np_io():\n",
    "    A = np.fromfile(\"data.dat\", np.int64)\n",
    "    return A.sum()\n",
    "\n",
    "res = example_np_io()\n",
    "if bodo.get_rank() == 0: print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Annotation (when file name is unknown at compile time)\n",
    "\n",
    "Bodo needs to know or infer the types for all data, but this is not always possible for input from files if file name is not known at compilation time.\n",
    "\n",
    "For example, suppose we have the following files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_files(n):\n",
    "    for i in range(n):\n",
    "        df = pd.DataFrame({\"A\": np.arange(5, dtype=np.int64)})\n",
    "        df.to_parquet(\"test\" + str(i) + \".pq\")\n",
    "\n",
    "generate_files(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we want to read them like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "BodoError",
     "evalue": "Parquet schema not available. Either path argument should be constant for Bodo to look at the file at compile time or schema should be provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBodoError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cef8b3ea8b00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# BodoError: Parquet schema not available. Either path argument should be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# constant for Bodo to look at the file at compile time or schema should be provided.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/bodo/bodo/numba_compat.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBodoError\u001b[0m: Parquet schema not available. Either path argument should be constant for Bodo to look at the file at compile time or schema should be provided."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def read_data(n):\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"test\" + str(i) + \".pq\"\n",
    "        df = pd.read_parquet(file_name)\n",
    "        print(df)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "result = read_data(5)\n",
    "# BodoError: Parquet schema not available. Either path argument should be\n",
    "# constant for Bodo to look at the file at compile time or schema should be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file names are computed at runtime, which doesn't allow the compiler to find the files and extract the schemas. As shown below, the solution is to use *type annotation* to provide data types to the compiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type annotation for Parquet files\n",
    "\n",
    "Example below uses the `locals` option of the decorator to provide the compiler with the schema of the local variable `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 50\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(locals={\"df\": {\"A\": bodo.int64[:]}})\n",
    "def read_data(n):\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"test\" + str(i) + \".pq\"\n",
    "        df = pd.read_parquet(file_name)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "result = read_data(5)\n",
    "if bodo.get_rank() == 0:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type annotation for CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CSV files, we can annotate types in the same way as pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 50\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "def generate_files(n):\n",
    "    for i in range(n):\n",
    "        df = pd.DataFrame({\"A\": np.arange(5, dtype=np.int64)})\n",
    "        df.to_csv(\"test\" + str(i) + \".csv\", index=False)\n",
    "\n",
    "@bodo.jit\n",
    "def read_data(n):\n",
    "    coltypes = {'A': np.int64}\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"test\" + str(i) + \".csv\"\n",
    "        df = pd.read_csv(file_name, names=coltypes.keys(), dtype=coltypes, header=0)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "n = 5\n",
    "if bodo.get_rank() == 0:\n",
    "    generate_files(n)\n",
    "bodo.barrier()\n",
    "result = read_data(n)\n",
    "if bodo.get_rank() == 0:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bodo Caching\n",
    "\n",
    "In many situations, Bodo can save the binary resulting from the compilation of a function to disk, to be reused in future runs. This avoids the need to recompile functions the next time that you run your application.\n",
    "\n",
    "As we explained earlier, recompiling a function is only necessary when it is called with new input types, and the same applies to caching. In other words, an application can be run multiple times and process different data without having to recompile any code if the data types remain the same (which is the most common situation).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"\n",
    "<b>Warning:</b> Caching works in many (but not all) situations, and is disabled by default. See caching limitations below for more information.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching Example\n",
    "\n",
    "To cache a function, we only need to add the option `cache=True` to the JIT decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "Total execution time: 0.013 secs\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import time\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return df[[\"power\", \"speed\"]].mean()\n",
    "\n",
    "t0 = time.time()\n",
    "result = mean_power_speed()\n",
    "if bodo.get_rank() == 0:\n",
    "    print(result)\n",
    "    print(\"Total execution time:\", round(time.time() - t0, 3), \"secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time that the above code runs, Bodo compiles the function and caches it to disk. In subsequent runs, it will recover the function from cache and the execution time will be much faster as a result. You can try this out by running the above code multiple times, and changing between `cache=True` and `cache=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Location and Portability\n",
    "\n",
    "In most cases, the cache is saved in the `__pycache__` directory inside the directory where the source files are located.\n",
    "\n",
    "On Jupyter notebooks, the cache directory is called ``numba_cache`` and is located in ``IPython.paths.get_ipython_cache_dir()``. See [here](http://numba.pydata.org/numba-doc/latest/reference/envvars.html?#envvar-NUMBA_CACHE_DIR) for more information on these and other alternate cache locations. For example, when running in a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ipython-input-10825d883f44.mean_power_speed-4444615264.py38.1.nbc',\n",
       " 'ipython-input-10825d883f44.mean_power_speed-4444615264.py38.nbi']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import IPython\n",
    "\n",
    "cache_dir = IPython.paths.get_ipython_cache_dir() + \"/numba_cache\"\n",
    "print(\"Cache files:\")\n",
    "os.listdir(cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cached objects work across systems with the same CPU model and CPU features. Therefore, it is safe to share and reuse the contents in the cache directory on a different machine. See [here](http://numba.pydata.org/numba-doc/latest/developer/caching.html#cache-sharing) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Invalidation\n",
    "\n",
    "The cache is invalidated automatically when the corresponding source code is modified. One way to observe this behavior is to modify the above example after it has been cached a first time, by changing the name of the variable `df`. The next time that we run the code, Bodo will determine that the source code has been modified, invalidate the cache and recompile the function.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"\n",
    "<b>Warning:</b> It is sometimes necessary to clear the cache manually (see caching limitations below). To clear the cache, the cache files can simply be removed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Caching Limitations\n",
    "\n",
    "- Caching does not recognize changes in Bodo versions, and cached files from different versions may not work, thus requiring manual clearing of the cache.\n",
    "- Changes in compiled functions are not seen across files. For example, if we have a cached Bodo function that calls a cached Bodo function in a different file, and modify the latter, Bodo will not update its cache (and therefore run with the old version of the function).\n",
    "- Functions that use `objmode` cannot be cached.\n",
    "- Global variables are treated as compile-time constants. When a function is compiled, the value of any globals that the function uses are embedded in the binary at compilation time and remain constant. If the value of the global changes in the source code after compilation, the compiled object (and cache) will not rebind to the new value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features\n",
    "\n",
    "### Explicit Parallel Loops\n",
    "Sometimes explicit parallel loops are required since a program cannot be written in terms of data-parallel operators easily. In this case, one can use Bodo’s `prange` in place of `range` to specify that a loop can be parallelized. The user is required to make sure the loop does not have cross iteration dependencies except for supported reductions.\n",
    "\n",
    "The example below demonstrates a parallel loop with a reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "rank 0\n",
      "rank 0\n",
      "rank 0\n",
      "19.593985614757415\n",
      "[stdout:1] \n",
      "rank 1\n",
      "rank 1\n",
      "rank 1\n",
      "19.593985614757415\n",
      "[stdout:2] \n",
      "rank 2\n",
      "rank 2\n",
      "19.593985614757415\n",
      "[stdout:3] \n",
      "rank 3\n",
      "rank 3\n",
      "19.593985614757415\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import bodo\n",
    "from bodo import prange\n",
    "import numpy as np\n",
    "\n",
    "@bodo.jit\n",
    "def prange_test(n):\n",
    "    A = np.random.ranf(n)\n",
    "    s = 0\n",
    "    B = np.empty(n)\n",
    "    for i in prange(len(A)):\n",
    "        bodo.parallel_print(\"rank\", bodo.get_rank())\n",
    "        # A[i]: distributed data access with loop index\n",
    "        # s: a supported sum reduction\n",
    "        s += A[i]\n",
    "        # write array with loop index\n",
    "        B[i] = 2 * A[i]\n",
    "    return s + B.sum()\n",
    "\n",
    "res = prange_test(10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, reductions using +=, *=, min, and max operators are supported. Iterations are simply divided between processes and executed in parallel, but reductions are handled using data exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with non-Bodo APIs\n",
    "There are multiple methods for integration with APIs that Bodo does not support natively:\n",
    "1. Switch to python object mode inside jit functions\n",
    "2. Pass data in and out of jit functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object mode\n",
    "Object mode allows switching to a python intepreted context to be able to run non-jittable code. The main requirement is specifying the type of returned values. For example, the following code calls a Scipy function on data elements of a distributed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 2.5130300167369066\n",
      "[stdout:1] 2.5130300167369066\n",
      "[stdout:2] 2.5130300167369066\n",
      "[stdout:3] 2.5130300167369066\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import scipy.special as sc\n",
    "\n",
    "@bodo.jit\n",
    "def objmode_test(n):\n",
    "    A = np.random.ranf(n)\n",
    "    s = 0\n",
    "    for i in prange(len(A)):\n",
    "        x = A[i]\n",
    "        with bodo.objmode(y=\"float64\"):\n",
    "            y = sc.entr(x)  # call entropy function on each data element\n",
    "        s += y\n",
    "    return s\n",
    "\n",
    "res = objmode_test(10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Numba's documentation for [objmode](http://numba.pydata.org/numba-doc/latest/user/withobjmode.html#the-objmode-context-manager) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passing Distributed Data\n",
    "Bodo can receive or return chunks of distributed data to allow flexible integration with any non-Bodo Python code. The following example passes chunks of data to interpolate with Scipy, and returns interpolation results back to jit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 6.555500504321469\n",
      "[stdout:1] 6.555500504321469\n",
      "[stdout:2] 6.555500504321469\n",
      "[stdout:3] 6.555500504321469\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import scipy.interpolate\n",
    "\n",
    "@bodo.jit(distributed=[\"X\", \"Y\", \"X2\"])\n",
    "def dist_pass_test(n):\n",
    "    X = np.arange(n)\n",
    "    Y = np.exp(-X/3.0)\n",
    "    X2 = np.arange(0, n, 0.5)\n",
    "    return X, Y, X2\n",
    "\n",
    "X, Y, X2 = dist_pass_test(100)\n",
    "# clip potential out-of-range values\n",
    "X2 = np.minimum(np.maximum(X2, X[0]), X[-1])\n",
    "f = scipy.interpolate.interp1d(X, Y)\n",
    "Y2 = f(X2)\n",
    "\n",
    "@bodo.jit(distributed={'Y2'})\n",
    "def dist_pass_res(Y2):\n",
    "    return Y2.sum()\n",
    "\n",
    "res = dist_pass_res(Y2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "A simple approach for visualization is pulling data to the notebook process from execution engines and using Python visualization libraries. Distributed data can be gathered if there is enough memory on the local machine. Otherwise, a sample of data can be gathered. The example code below demonstrates gathering a portion of data for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def dist_gather_test(n):\n",
    "    X = np.arange(n)\n",
    "    Y = np.exp(-X/3.0)\n",
    "    return bodo.gatherv(Y[::10])  # gather every 10th element\n",
    "\n",
    "\n",
    "Y_sample = dist_gather_test(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12abfcc10>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "Y_sample = view['Y_sample'][0]\n",
    "plt.plot(Y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Compilation Tips\n",
    "\n",
    "The general recommendation is to **compile the code that is performance critical and/or requires scaling**.\n",
    "\n",
    "1. Don’t use Bodo for scripts that set up infrastucture or do initializations.\n",
    "2. Only use Bodo for data processing and analytics code.\n",
    "\n",
    "This reduces the risk of hitting unsupported features and reduces compilation time. To do so, simply factor out the code that needs to be compiled by Bodo and pass data into Bodo compiled functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation Errors\n",
    "\n",
    "The most common reason is that the code relies on features that Bodo currently does not support, so it’s important to understand the limitations of Bodo. There are 4 main limitations:\n",
    "\n",
    "1. Not supported Pandas API (see [here](http://docs.bodo.ai/latest/source/pandas.html#pandas))\n",
    "2. Not supported NumPy API (see [here](http://docs.bodo.ai/latest/source/numpy.html#numpy))\n",
    "3. Not supported Python features or datatypes (see [here](http://docs.bodo.ai/latest/source/not_supported.html#unsupported-python-constructs))\n",
    "4. Not supported Python programs due to type instability\n",
    "\n",
    "Solutions:\n",
    "\n",
    "1. Make sure your code works in Python (using a small sample dataset): a lot of the times a Bodo decorated function doesn’t compile, but it does not compile in Python either.\n",
    "2. Replace unsupported operations with supported operations if possible.\n",
    "3. Refactor the code to partially use regular Python, explained in \"Integration with non-Bodo APIs\" section.\n",
    "\n",
    "For example, the code below uses heterogenous list values inside `a` which cannot be typed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in bodo mode pipeline (step: <class 'bodo.transforms.typing_pass.BodoTypeInference'>)\nUndecided type $26load_method.3 := <undecided>\n[1] During: resolving caller type: $26load_method.3\n[2] During: typing of call at <ipython-input-34-f4457c83a698> (5)\n\n\nFile \"<ipython-input-34-f4457c83a698>\", line 5:\ndef f(n):\n    <source elided>\n    for i in range(n):\n        a.append([i, \"a\"])\n        ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f4457c83a698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/bodo/bodo/numba_compat.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"typing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bodo/bodo/numba_compat.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/numba/numba/core/utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in bodo mode pipeline (step: <class 'bodo.transforms.typing_pass.BodoTypeInference'>)\nUndecided type $26load_method.3 := <undecided>\n[1] During: resolving caller type: $26load_method.3\n[2] During: typing of call at <ipython-input-34-f4457c83a698> (5)\n\n\nFile \"<ipython-input-34-f4457c83a698>\", line 5:\ndef f(n):\n    <source elided>\n    for i in range(n):\n        a.append([i, \"a\"])\n        ^\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(n):\n",
    "    a = [[-1, \"a\"]]\n",
    "    for i in range(n):\n",
    "        a.append([i, \"a\"])\n",
    "    return a\n",
    "\n",
    "print(f(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this use case can be rewritten to use tuple values instead of lists since values don't change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1, 'a'), (0, 'a'), (1, 'a'), (2, 'a')]\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(n):\n",
    "    a = [(-1, \"a\")]\n",
    "    for i in range(n):\n",
    "        a.append((i, \"a\"))\n",
    "    return a\n",
    "\n",
    "print(f(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Schema Stability\n",
    "\n",
    "Deterministic dataframe schemas (column names and types), which are required in most data systems, are key for type stability. For example, variable `df` in example below could be either a single column dataframe or a two column one – Bodo cannot determine it at compilation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in bodo mode pipeline (step: <class 'bodo.transforms.typing_pass.BodoTypeInference'>)\nCannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), False) and dataframe((array(int64, 1d, C), array(int64, 1d, C)), RangeIndexType(none), ('A', 'C'), False) for 'df.2', defined at <ipython-input-36-0427977302c7> (8)\n\nFile \"<ipython-input-36-0427977302c7>\", line 8:\ndef f(a):\n    <source elided>\n\n    return df.mean()\n    ^\n\n[1] During: typing of assignment at <ipython-input-36-0427977302c7> (8)\n\nFile \"<ipython-input-36-0427977302c7>\", line 8:\ndef f(a):\n    <source elided>\n\n    return df.mean()\n    ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0427977302c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# TypeError: Cannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# and dataframe((array(int64, 1d, C), array(int64, 1d, C)), RangeIndexType(none), ('A', 'C'), False) for 'df'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bodo/bodo/numba_compat.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"typing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bodo/bodo/numba_compat.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/numba/numba/core/utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in bodo mode pipeline (step: <class 'bodo.transforms.typing_pass.BodoTypeInference'>)\nCannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), False) and dataframe((array(int64, 1d, C), array(int64, 1d, C)), RangeIndexType(none), ('A', 'C'), False) for 'df.2', defined at <ipython-input-36-0427977302c7> (8)\n\nFile \"<ipython-input-36-0427977302c7>\", line 8:\ndef f(a):\n    <source elided>\n\n    return df.mean()\n    ^\n\n[1] During: typing of assignment at <ipython-input-36-0427977302c7> (8)\n\nFile \"<ipython-input-36-0427977302c7>\", line 8:\ndef f(a):\n    <source elided>\n\n    return df.mean()\n    ^\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(a):\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    df2 = pd.DataFrame({\"A\": [1, 3, 4], \"C\": [-1, -2, -3]})\n",
    "    if len(a) > 3:\n",
    "        df = df.merge(df2)\n",
    "\n",
    "    return df.mean()\n",
    "\n",
    "print(f([2, 3]))\n",
    "# TypeError: Cannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), False)\n",
    "# and dataframe((array(int64, 1d, C), array(int64, 1d, C)), RangeIndexType(none), ('A', 'C'), False) for 'df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message means that Bodo cannot find a type that can unify the two types into a single type. This code can be refactored so that the if control flow is executed in regular Python context, but the rest of computation is in Bodo functions. For example, one could use two versions of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bodo/bodo/transforms/distributed_analysis.py:233: BodoWarning: No parallelism found for function 'f2'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  \"information.\".format(self.func_ir.func_id.func_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    2.0\n",
      "C   -1.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f1():\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    return df.mean()\n",
    "\n",
    "@bodo.jit\n",
    "def f2():\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    df2 = pd.DataFrame({\"A\": [1, 3, 4], \"C\": [-1, -2, -3]})\n",
    "    df = df.merge(df2)\n",
    "    return df.mean()\n",
    "\n",
    "a = [2, 3]\n",
    "if len(a) > 3:\n",
    "    print(f1())\n",
    "else:\n",
    "    print(f2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common place where schema stability may be compromised is in passing non-constant list of key column names to dataframe operations such as `groupby`, `merge` and `sort_values`. In these operations, Bodo should be able to deduce the list of key column names at compile time in order to determine the output dataframe schema. For example, the program below is potentially type unstable since Bodo may not be able to infer `column_list` during compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "BodoError",
     "evalue": "groupby(): 'by' parameter only supports a constant column label or column labels.\n\nFile \"<ipython-input-39-20679220db65>\", line 5:\ndef f(a, i):\n    <source elided>\n    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n    return df.groupby(column_list).sum()\n    ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBodoError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-20679220db65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# BodoError: groupby(): 'by' parameter only supports a constant column label or column labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bodo/bodo/numba_compat.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBodoError\u001b[0m: groupby(): 'by' parameter only supports a constant column label or column labels.\n\nFile \"<ipython-input-39-20679220db65>\", line 5:\ndef f(a, i):\n    <source elided>\n    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n    return df.groupby(column_list).sum()\n    ^\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(a, i):\n",
    "    column_list = a[:i]  # some computation that cannot be inferred statically\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n",
    "    return df.groupby(column_list).sum()\n",
    "\n",
    "a = [\"A\", \"B\"]\n",
    "i = 1\n",
    "f(a, i)\n",
    "# BodoError: groupby(): 'by' parameter only supports a constant column label or column labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code can most often be refactored to compute the key list in regular Python and pass as argument to Bodo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehsan/dev/bodo/bodo/transforms/distributed_analysis.py:229: BodoWarning: No parallelism found for function 'f'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    B\n",
       "A    \n",
       "1  10\n",
       "2   5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(column_list):\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n",
    "    return df.groupby(column_list).sum()\n",
    "\n",
    "a = [\"A\", \"B\"]\n",
    "i = 1\n",
    "column_list = a[:i]\n",
    "f(column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nullable Integers in Pandas\n",
    "\n",
    "DataFrame and Series objects with integer data need special care due to [integer NA issues in Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#nan-integer-na-values-and-na-type-promotions). By default, Pandas dynamically converts integer columns to floating point when missing values (NAs) are needed, which can result in loss of precision as well as type instability.\n",
    "\n",
    "Pandas introduced [a new nullable integer data type](https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html#integer-na) that can solve this issue, which is also supported by Bodo. For example, this code reads column A into a nullable integer array (the capital “I” denotes nullable integer type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A    B\n",
       "0    11  1.2\n",
       "1    -2  NaN\n",
       "2  <NA>  3.1\n",
       "3     4 -0.1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    \"11,1.2\\n\"\n",
    "    \"-2,\\n\"\n",
    "    \",3.1\\n\"\n",
    "    \"4,-0.1\\n\"\n",
    ")\n",
    "\n",
    "with open(\"data.csv\", \"w\") as f:\n",
    "    f.write(data)\n",
    "\n",
    "\n",
    "@bodo.jit(distributed=[\"df\"])\n",
    "def f():\n",
    "    dtype = {\"A\": \"Int64\", \"B\": \"float64\"}\n",
    "    df = pd.read_csv(\"data.csv\", dtype = dtype, names = dtype.keys())\n",
    "    return df\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxing/Unboxing Overheads\n",
    "\n",
    "Bodo uses efficient native data structures which can be different than Python. When Python values are passed to Bodo, they are *unboxed* to native representation. On the other hand, returning Bodo values requires *boxing* to Python objects. Boxing and unboxing can have significant overhead depending on size and type of data. For example, passing string column between Python/Bodo repeatedly can be expensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        2\n",
      "2        2\n",
      "3        3\n",
      "4        3\n",
      "        ..\n",
      "3897    00\n",
      "3898    00\n",
      "3899    00\n",
      "3900    00\n",
      "3901    00\n",
      "Name: hr, Length: 3902, dtype: object\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(distributed=[\"df\"])\n",
    "def gen_data():\n",
    "    df = pd.read_parquet(\"cycling_dataset.pq\")\n",
    "    df[\"hr\"] = df[\"hr\"].astype(str)\n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=[\"df\", \"x\"])\n",
    "def mean_power(df):\n",
    "    x = df.hr.str[1:]\n",
    "    return x\n",
    "\n",
    "df = gen_data()\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can try to keep data in Bodo functions as much as possible to avoid boxing/unboxing overheads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        2\n",
      "2        2\n",
      "3        3\n",
      "4        3\n",
      "        ..\n",
      "3897    00\n",
      "3898    00\n",
      "3899    00\n",
      "3900    00\n",
      "3901    00\n",
      "Name: hr, Length: 3902, dtype: object\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(distributed=[\"df\"])\n",
    "def gen_data():\n",
    "    df = pd.read_parquet(\"cycling_dataset.pq\")\n",
    "    df[\"hr\"] = df[\"hr\"].astype(str)\n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=[\"df\", \"x\"])\n",
    "def mean_power(df):\n",
    "    x = df.hr.str[1:]\n",
    "    return x\n",
    "\n",
    "@bodo.jit\n",
    "def f():\n",
    "    df = gen_data()\n",
    "    res = mean_power(df)\n",
    "    print(res)\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions using `re`\n",
    "\n",
    "Bodo supports string processing using Pandas and the `re` standard package, offering significant flexibility for string processing applications. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehsan/dev/bodo/bodo/transforms/distributed_analysis.py:229: BodoWarning: No parallelism found for function 'f'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    3\n",
       "2    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "@bodo.jit\n",
    "def f(S):\n",
    "    def g(a):\n",
    "        res = 0\n",
    "        if re.search(\".*AB.*\", a):\n",
    "            res = 3\n",
    "        if re.search(\".*23.*\", a):\n",
    "            res = 5\n",
    "        return res\n",
    "\n",
    "    return S.map(g)\n",
    "\n",
    "S = pd.Series([\"AABCDE\", \"BBABCE\", \"1234\"])\n",
    "f(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
