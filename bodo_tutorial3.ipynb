{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo Extended Tutorial\n",
    "\n",
    "This is a continuation of the \"Getting Started\" tutorial. You are encouraged to visit that tutorial first if you have not done so already. In this tutorial, we will explain core Bodo concepts in more detail, introduce more Bodo features, and discuss more advanced topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Please follow the [bodo installation](http://docs.bodo.ai/latest/source/install.html) and [Jupyter Notebook Setup](http://docs.bodo.ai/latest/source/jupyter.html) pages to setup the environment. Also, make sure MPI engines are started in the `IPython Clusters` tab (or using `ipcluster start -n 4 --profile=mpi` in command line)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bodo Basics\n",
    "\n",
    "## JIT (Just-in-time) Compilation Workflow\n",
    "\n",
    "Bodo provides a just-in-time (JIT) compilation workflow using the `@bodo.jit` decorator, which replaces a Python function with a so-called `Dispatcher` object. Bodo compiles the function the first time a Dispatcher object is called and reuses the compiled version afterwards. The function is recompiled only if the same function is called with different argument types (not often in practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUDispatcher(<function f at 0x130714940>)\n",
      "   A\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "   A\n",
      "0  2\n",
      "1  3\n",
      "2  4\n",
      "     A\n",
      "0  2.2\n",
      "1  3.2\n",
      "2  4.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def f(n, a):\n",
    "    df = pd.DataFrame({'A': np.arange(n) + a})\n",
    "    return df.head(3)\n",
    "\n",
    "print(f)\n",
    "print(f(8, 1))  # compiles for (int, int) input types\n",
    "print(f(8, 2))  # same input types, no need to compile\n",
    "print(f(8, 2.2))  # compiles for (int, float) input types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this is completely transparent to the caller, and does not affect any Python code calling the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Execution Model\n",
    "\n",
    "As we saw in the \"Getting Started\" tutorial, Bodo transforms functions for parallel execution. However, the dispatcher does not launch processes or threads on the fly. Instead, the Python application (including non-Bodo code) is intended to be executed under an MPI Single Program Multiple Data ([SPMD](https://en.wikipedia.org/wiki/SPMD)) paradigm, where MPI processes are launched in the beginning and all run the same code.\n",
    "\n",
    "\n",
    "For example, we can save an example code in a file and use *mpiexec* to launch 4 processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n",
      "5  6\n",
      "6  7\n",
      "7  8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=[\"df\"])\n",
    "def f(n, a):\n",
    "    df = pd.DataFrame({'A': np.arange(n) + a})\n",
    "    return df\n",
    "\n",
    "print(f(8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following commands were written to file `test_bodo.py`:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import bodo\n",
      "\n",
      "@bodo.jit(distributed=[\"df\"])\n",
      "def f(n, a):\n",
      "    df = pd.DataFrame({'A': np.arange(n) + a})\n",
      "    return df\n",
      "\n",
      "print(f(8, 1))\n"
     ]
    }
   ],
   "source": [
    "%save -f test_bodo.py 2 # cell number of previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A\r\n",
      "0  1\r\n",
      "1  2\r\n",
      "   A\r\n",
      "2  3\r\n",
      "3  4\r\n",
      "   A\r\n",
      "4  5\r\n",
      "5  6\r\n",
      "   A\r\n",
      "6  7\r\n",
      "7  8\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 4 python test_bodo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `mpiexec` launches 4 Python processes, each of which executes the same `test_bodo.py` file.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b>\n",
    "\n",
    "- Python codes outside of Bodo functions execute sequentially on every process.\n",
    "- Bodo functions run in parallel assuming that Bodo is able to parallelize them. Otherwise, they also run sequentially on every process. Bodo warns if it does not find parallelism (more details later).\n",
    "\n",
    "</div>\n",
    "\n",
    "Note how the prints, which are regular Python code executed outside of Bodo, run for each process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Jupyter notebook, parallel execution happens in very much the same way. We start a set of MPI engines through `ipyparallel` and activate a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client(profile='mpi')\n",
    "view = c[:]\n",
    "view.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this initialization, any code that we run in the notebook with `%%px --block` is sent for execution on all MPI engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "   A\n",
      "0  0\n",
      "1  1\n",
      "[stdout:1] \n",
      "   A\n",
      "2  2\n",
      "3  3\n",
      "[stdout:2] \n",
      "   A\n",
      "4  4\n",
      "5  5\n",
      "[stdout:3] \n",
      "   A\n",
      "6  6\n",
      "7  7\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def f(n):\n",
    "    df = pd.DataFrame({'A': np.arange(n)})\n",
    "    return df\n",
    "\n",
    "print(f(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel APIs\n",
    "\n",
    "Bodo provides a limited number of parallel APIs to support advanced cases that may need them. Example below demonstrates running some code only on one process, and then synchronizing all processes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] rank 0 done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:2]: \u001b[0m0"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-04-28T21:48:51.112874",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "2ccca41f-f9812ce2af5c86360db03749",
      "error": null,
      "execute_input": "\n# some work on only rank 0\nif bodo.get_rank() == 0:\n    print(\"rank 0 done\")\n\n# make sure all processes are synchronized\n# (e.g. all processes need to see effect of rank 0's work)\nbodo.barrier()  \n",
      "execute_result": {
       "data": {
        "text/plain": "0"
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "ef4b6f1d-83c42f1924fd5741e01301e2_5",
      "outputs": [],
      "received": "2020-04-28T21:48:51.120581",
      "started": "2020-04-28T21:48:51.103730",
      "status": "ok",
      "stderr": "",
      "stdout": "rank 0 done\n",
      "submitted": "2020-04-28T21:48:51.100447"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:2]: \u001b[0m0"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-04-28T21:48:51.112632",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "b8dddd95-d1959d96c70dce7275e84ccd",
      "error": null,
      "execute_input": "\n# some work on only rank 0\nif bodo.get_rank() == 0:\n    print(\"rank 0 done\")\n\n# make sure all processes are synchronized\n# (e.g. all processes need to see effect of rank 0's work)\nbodo.barrier()  \n",
      "execute_result": {
       "data": {
        "text/plain": "0"
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "ef4b6f1d-83c42f1924fd5741e01301e2_6",
      "outputs": [],
      "received": "2020-04-28T21:48:51.119063",
      "started": "2020-04-28T21:48:51.103892",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-04-28T21:48:51.100617"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[2:2]: \u001b[0m0"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-04-28T21:48:51.112612",
      "data": {},
      "engine_id": 2,
      "engine_uuid": "d5437b14-0f08f2d1a2a8f8227cc0ecce",
      "error": null,
      "execute_input": "\n# some work on only rank 0\nif bodo.get_rank() == 0:\n    print(\"rank 0 done\")\n\n# make sure all processes are synchronized\n# (e.g. all processes need to see effect of rank 0's work)\nbodo.barrier()  \n",
      "execute_result": {
       "data": {
        "text/plain": "0"
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "ef4b6f1d-83c42f1924fd5741e01301e2_7",
      "outputs": [],
      "received": "2020-04-28T21:48:51.115470",
      "started": "2020-04-28T21:48:51.103971",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-04-28T21:48:51.100742"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[3:2]: \u001b[0m0"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-04-28T21:48:51.112754",
      "data": {},
      "engine_id": 3,
      "engine_uuid": "ba8a91b5-edd7c1da22f80d88ff4ee924",
      "error": null,
      "execute_input": "\n# some work on only rank 0\nif bodo.get_rank() == 0:\n    print(\"rank 0 done\")\n\n# make sure all processes are synchronized\n# (e.g. all processes need to see effect of rank 0's work)\nbodo.barrier()  \n",
      "execute_result": {
       "data": {
        "text/plain": "0"
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "ef4b6f1d-83c42f1924fd5741e01301e2_8",
      "outputs": [],
      "received": "2020-04-28T21:48:51.117465",
      "started": "2020-04-28T21:48:51.104101",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-04-28T21:48:51.100855"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "# some work on only rank 0\n",
    "if bodo.get_rank() == 0:\n",
    "    print(\"rank 0 done\")\n",
    "\n",
    "# make sure all processes are synchronized\n",
    "# (e.g. all processes need to see effect of rank 0's work)\n",
    "bodo.barrier()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> As in this example, it is possible to have each process follow a different control flow, but all processes must always call the same Bodo functions in the same order.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Distribution\n",
    "\n",
    "Bodo parallelize computation by dividing data into separate chunks across processes. However, some data handled by a Bodo function may not be divided into chunks. There are are two main data distribution schemes:\n",
    "\n",
    "- Replicated (*REP*): the data associated with the variable is the same on every process.\n",
    "- One-dimensional (*1D*): the data is divided into chunks, split along one dimension (rows of a dataframe or first dimension of an array)\n",
    "\n",
    "Bodo finds distribution of variables automatically, using the nature of the computation that produces them. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:1] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:2] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:3] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    m = df[[\"power\", \"speed\"]].mean()\n",
    "    return m\n",
    "\n",
    "res = mean_power_speed()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `df` is parallelized but `m` is replicated, even though it is a Series. Semantically, it makes sense for output of `mean` operation to be replicated on all processors, since it is a reduction and produces \"small\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Diagnostics\n",
    "\n",
    "The distributions found by Bodo can be printed either by setting `BODO_DISTRIBUTED_DIAGNOSTICS=1` or calling `distributed_diagnostics()` on the compiled function. Let's examine the previous example's distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Distributed diagnostics for function mean_power_speed, <ipython-input-3-b6752a146201> (1)\n",
      "\n",
      "Data distributions:\n",
      "   power.362                1D_Block\n",
      "   speed.363                1D_Block\n",
      "   $A.599.945               1D_Block\n",
      "   $A.662.955               1D_Block\n",
      "   $data.571.966            REP\n",
      "   $12call_method.5.929     REP\n",
      "   $66call_method.31.589    REP\n",
      "   $m.968                   REP\n",
      "   $30return_value.12       REP\n",
      "\n",
      "Parfor distributions:\n",
      "   1                    1D_Block\n",
      "   2                    1D_Block\n",
      "\n",
      "Distributed listing for function mean_power_speed, <ipython-input-3-b6752a146201> (1)\n",
      "--------------------------------------------------| parfor_id/variable: distribution\n",
      "@bodo.jit                                         | \n",
      "def mean_power_speed():                           | \n",
      "    df = pd.read_parquet('cycling_dataset.pq')----| power.362: 1D_Block, speed.363: 1D_Block\n",
      "    m = df[[\"power\", \"speed\"]].mean()-------------| $A.599.945: 1D_Block, $A.662.955: 1D_Block\n",
      "    return m--------------------------------------| $30return_value.12: REP\n",
      "\n",
      "Distributed analysis set $data.571.966 as replicated due to call to function 'np.asarray' (unsupported function or usage)\n",
      "Distributed analysis set $12call_method.5.929 as replicated due to call to function 'bodo.libs.str_arr_ext.str_arr_from_sequence' (unsupported function or usage)\n",
      "Distributed analysis replicated output variable $30return_value.12. Set distributed flag for the original variable if distributed partitions should be returned.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "mean_power_speed.distributed_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are renamed due to optimization. The output shows that `power` and `speed` columns of `df` are distributed (`1D_Block`) but `m` is replicated (`REP`). This is because `df` is output of `read_parquet` and input of `mean`, both of which can be distributed. `m` is output of `mean`, which is always replicated (available on every process)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Arguments and Return Values\n",
    "\n",
    "Now let's see what happens if we pass the data into the Bodo function as a function parameter but don't mark it as distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:1] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:2] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "[stdout:3] \n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "/Users/ehsan/dev/bodo/bodo/transforms/distributed_analysis.py:229: BodoWarning: No parallelism found for function 'mean_power_speed'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed(df):\n",
    "    m = df[[\"power\", \"speed\"]].mean()\n",
    "    return m\n",
    "\n",
    "df = pd.read_parquet('cycling_dataset.pq')\n",
    "res = mean_power_speed(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program runs and returns the same correct value as before, but everything is replicated on all processes and *there is no parallelism!* Bodo's warning indicates this explicitly. Therefore, each process reads the whole data file and calculates the mean of the dataframe independently.\n",
    "\n",
    "This is because data is passed to Bodo as argument without setting the distributed flag, and Bodo assumes correctly that the data is replicated. Bodo then follows dependencies and replicates the whole program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, return values will be replicated by default, since data is passed to regular Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr   latitude  \\\n",
      "0              0  185.800003       51      3.460000   81  30.313309   \n",
      "1              1  185.800003       68      7.170000   82  30.313277   \n",
      "2              2  186.399994       38     11.040000   82  30.313243   \n",
      "3              3  186.800003       38     15.180000   83  30.313212   \n",
      "4              4  186.600006       38     19.430000   83  30.313172   \n",
      "...          ...         ...      ...           ...  ...        ...   \n",
      "3897        1127  178.199997        0  22014.929688  100  30.313483   \n",
      "3898        1128  178.199997        0  22018.220703  100  30.313482   \n",
      "3899        1129  178.199997        0  22021.179688  100  30.313485   \n",
      "3900        1130  178.399994        0  22024.150391  100  30.313489   \n",
      "3901        1131  178.399994        0  22027.009766  100  30.313492   \n",
      "\n",
      "      longitude  power  speed                time  \n",
      "0    -97.732711     45  3.459 2016-10-20 22:01:26  \n",
      "1    -97.732715      0  3.710 2016-10-20 22:01:27  \n",
      "2    -97.732717     42  3.874 2016-10-20 22:01:28  \n",
      "3    -97.732720      5  4.135 2016-10-20 22:01:29  \n",
      "4    -97.732723      1  4.250 2016-10-20 22:01:30  \n",
      "...         ...    ...    ...                 ...  \n",
      "3897 -97.733165      0  3.497 2016-10-20 23:14:31  \n",
      "3898 -97.733141      0  3.289 2016-10-20 23:14:32  \n",
      "3899 -97.733114      0  2.969 2016-10-20 23:14:33  \n",
      "3900 -97.733087      0  2.969 2016-10-20 23:14:34  \n",
      "3901 -97.733063      0  2.853 2016-10-20 23:14:35  \n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:1] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr   latitude  \\\n",
      "0              0  185.800003       51      3.460000   81  30.313309   \n",
      "1              1  185.800003       68      7.170000   82  30.313277   \n",
      "2              2  186.399994       38     11.040000   82  30.313243   \n",
      "3              3  186.800003       38     15.180000   83  30.313212   \n",
      "4              4  186.600006       38     19.430000   83  30.313172   \n",
      "...          ...         ...      ...           ...  ...        ...   \n",
      "3897        1127  178.199997        0  22014.929688  100  30.313483   \n",
      "3898        1128  178.199997        0  22018.220703  100  30.313482   \n",
      "3899        1129  178.199997        0  22021.179688  100  30.313485   \n",
      "3900        1130  178.399994        0  22024.150391  100  30.313489   \n",
      "3901        1131  178.399994        0  22027.009766  100  30.313492   \n",
      "\n",
      "      longitude  power  speed                time  \n",
      "0    -97.732711     45  3.459 2016-10-20 22:01:26  \n",
      "1    -97.732715      0  3.710 2016-10-20 22:01:27  \n",
      "2    -97.732717     42  3.874 2016-10-20 22:01:28  \n",
      "3    -97.732720      5  4.135 2016-10-20 22:01:29  \n",
      "4    -97.732723      1  4.250 2016-10-20 22:01:30  \n",
      "...         ...    ...    ...                 ...  \n",
      "3897 -97.733165      0  3.497 2016-10-20 23:14:31  \n",
      "3898 -97.733141      0  3.289 2016-10-20 23:14:32  \n",
      "3899 -97.733114      0  2.969 2016-10-20 23:14:33  \n",
      "3900 -97.733087      0  2.969 2016-10-20 23:14:34  \n",
      "3901 -97.733063      0  2.853 2016-10-20 23:14:35  \n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:2] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr   latitude  \\\n",
      "0              0  185.800003       51      3.460000   81  30.313309   \n",
      "1              1  185.800003       68      7.170000   82  30.313277   \n",
      "2              2  186.399994       38     11.040000   82  30.313243   \n",
      "3              3  186.800003       38     15.180000   83  30.313212   \n",
      "4              4  186.600006       38     19.430000   83  30.313172   \n",
      "...          ...         ...      ...           ...  ...        ...   \n",
      "3897        1127  178.199997        0  22014.929688  100  30.313483   \n",
      "3898        1128  178.199997        0  22018.220703  100  30.313482   \n",
      "3899        1129  178.199997        0  22021.179688  100  30.313485   \n",
      "3900        1130  178.399994        0  22024.150391  100  30.313489   \n",
      "3901        1131  178.399994        0  22027.009766  100  30.313492   \n",
      "\n",
      "      longitude  power  speed                time  \n",
      "0    -97.732711     45  3.459 2016-10-20 22:01:26  \n",
      "1    -97.732715      0  3.710 2016-10-20 22:01:27  \n",
      "2    -97.732717     42  3.874 2016-10-20 22:01:28  \n",
      "3    -97.732720      5  4.135 2016-10-20 22:01:29  \n",
      "4    -97.732723      1  4.250 2016-10-20 22:01:30  \n",
      "...         ...    ...    ...                 ...  \n",
      "3897 -97.733165      0  3.497 2016-10-20 23:14:31  \n",
      "3898 -97.733141      0  3.289 2016-10-20 23:14:32  \n",
      "3899 -97.733114      0  2.969 2016-10-20 23:14:33  \n",
      "3900 -97.733087      0  2.969 2016-10-20 23:14:34  \n",
      "3901 -97.733063      0  2.853 2016-10-20 23:14:35  \n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:3] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr   latitude  \\\n",
      "0              0  185.800003       51      3.460000   81  30.313309   \n",
      "1              1  185.800003       68      7.170000   82  30.313277   \n",
      "2              2  186.399994       38     11.040000   82  30.313243   \n",
      "3              3  186.800003       38     15.180000   83  30.313212   \n",
      "4              4  186.600006       38     19.430000   83  30.313172   \n",
      "...          ...         ...      ...           ...  ...        ...   \n",
      "3897        1127  178.199997        0  22014.929688  100  30.313483   \n",
      "3898        1128  178.199997        0  22018.220703  100  30.313482   \n",
      "3899        1129  178.199997        0  22021.179688  100  30.313485   \n",
      "3900        1130  178.399994        0  22024.150391  100  30.313489   \n",
      "3901        1131  178.399994        0  22027.009766  100  30.313492   \n",
      "\n",
      "      longitude  power  speed                time  \n",
      "0    -97.732711     45  3.459 2016-10-20 22:01:26  \n",
      "1    -97.732715      0  3.710 2016-10-20 22:01:27  \n",
      "2    -97.732717     42  3.874 2016-10-20 22:01:28  \n",
      "3    -97.732720      5  4.135 2016-10-20 22:01:29  \n",
      "4    -97.732723      1  4.250 2016-10-20 22:01:30  \n",
      "...         ...    ...    ...                 ...  \n",
      "3897 -97.733165      0  3.497 2016-10-20 23:14:31  \n",
      "3898 -97.733141      0  3.289 2016-10-20 23:14:32  \n",
      "3899 -97.733114      0  2.969 2016-10-20 23:14:33  \n",
      "3900 -97.733087      0  2.969 2016-10-20 23:14:34  \n",
      "3901 -97.733063      0  2.853 2016-10-20 23:14:35  \n",
      "\n",
      "[3902 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "/Users/ehsan/dev/bodo/bodo/transforms/distributed_analysis.py:229: BodoWarning: No parallelism found for function 'mean_power_speed'. This could be due to unsupported usage. See distributed diagnostics for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return df\n",
    "\n",
    "df = mean_power_speed()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> Bodo assumes that input parameters and return values are replicated, unless if specified using `distributed` flag. This can lead to replication of the whole program due to dependencies.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Distributed Data to Bodo\n",
    "\n",
    "Bodo functions may require distributed arguments and return values in some cases such as passing distributed data across Bodo functions. This can be achieved using the `distributed` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "total size 3902\n",
      "chunk size 976\n",
      "102.07842132239877\n",
      "[stdout:1] \n",
      "chunk size 976\n",
      "102.07842132239877\n",
      "[stdout:2] \n",
      "chunk size 976\n",
      "102.07842132239877\n",
      "[stdout:3] \n",
      "chunk size 974\n",
      "102.07842132239877\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def read_data():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    print(\"total size\", len(df))\n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def mean_power(df):\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "df = read_data()\n",
    "# df is a chunk of data on each process\n",
    "print(\"chunk size\", len(df))\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scattering Data\n",
    "\n",
    "One can distribute data manually by *scattering* data from one process to all processes. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 102.07842132239877\n",
      "[stdout:1] 102.07842132239877\n",
      "[stdout:2] 102.07842132239877\n",
      "[stdout:3] 102.07842132239877\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def mean_power(df):\n",
    "    x = df.power.mean()\n",
    "    return x\n",
    "\n",
    "df = None\n",
    "# only rank 0 reads the data\n",
    "if bodo.get_rank() == 0:\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "\n",
    "df = bodo.scatterv(df)\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data\n",
    "\n",
    "One can *gather* distributed data into a single process manually. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr   latitude  \\\n",
      "0              0  185.800003       51      3.460000   81  30.313309   \n",
      "1              1  185.800003       68      7.170000   82  30.313277   \n",
      "2              2  186.399994       38     11.040000   82  30.313243   \n",
      "3              3  186.800003       38     15.180000   83  30.313212   \n",
      "4              4  186.600006       38     19.430000   83  30.313172   \n",
      "...          ...         ...      ...           ...  ...        ...   \n",
      "3897        1127  178.199997        0  22014.929688  100  30.313483   \n",
      "3898        1128  178.199997        0  22018.220703  100  30.313482   \n",
      "3899        1129  178.199997        0  22021.179688  100  30.313485   \n",
      "3900        1130  178.399994        0  22024.150391  100  30.313489   \n",
      "3901        1131  178.399994        0  22027.009766  100  30.313492   \n",
      "\n",
      "      longitude  power  speed                time  \n",
      "0    -97.732711     45  3.459 2016-10-20 22:01:26  \n",
      "1    -97.732715      0  3.710 2016-10-20 22:01:27  \n",
      "2    -97.732717     42  3.874 2016-10-20 22:01:28  \n",
      "3    -97.732720      5  4.135 2016-10-20 22:01:29  \n",
      "4    -97.732723      1  4.250 2016-10-20 22:01:30  \n",
      "...         ...    ...    ...                 ...  \n",
      "3897 -97.733165      0  3.497 2016-10-20 23:14:31  \n",
      "3898 -97.733141      0  3.289 2016-10-20 23:14:32  \n",
      "3899 -97.733114      0  2.969 2016-10-20 23:14:33  \n",
      "3900 -97.733087      0  2.969 2016-10-20 23:14:34  \n",
      "3901 -97.733063      0  2.853 2016-10-20 23:14:35  \n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:1] \n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, altitude, cadence, distance, hr, latitude, longitude, power, speed, time]\n",
      "Index: []\n",
      "[stdout:2] \n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, altitude, cadence, distance, hr, latitude, longitude, power, speed, time]\n",
      "Index: []\n",
      "[stdout:3] \n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, altitude, cadence, distance, hr, latitude, longitude, power, speed, time]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return bodo.gatherv(df)\n",
    "\n",
    "df = mean_power()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, distributed data can be gathered and sent to all processes, effectively replicating the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr   latitude  \\\n",
      "0              0  185.800003       51      3.460000   81  30.313309   \n",
      "1              1  185.800003       68      7.170000   82  30.313277   \n",
      "2              2  186.399994       38     11.040000   82  30.313243   \n",
      "3              3  186.800003       38     15.180000   83  30.313212   \n",
      "4              4  186.600006       38     19.430000   83  30.313172   \n",
      "...          ...         ...      ...           ...  ...        ...   \n",
      "3897        1127  178.199997        0  22014.929688  100  30.313483   \n",
      "3898        1128  178.199997        0  22018.220703  100  30.313482   \n",
      "3899        1129  178.199997        0  22021.179688  100  30.313485   \n",
      "3900        1130  178.399994        0  22024.150391  100  30.313489   \n",
      "3901        1131  178.399994        0  22027.009766  100  30.313492   \n",
      "\n",
      "      longitude  power  speed                time  \n",
      "0    -97.732711     45  3.459 2016-10-20 22:01:26  \n",
      "1    -97.732715      0  3.710 2016-10-20 22:01:27  \n",
      "2    -97.732717     42  3.874 2016-10-20 22:01:28  \n",
      "3    -97.732720      5  4.135 2016-10-20 22:01:29  \n",
      "4    -97.732723      1  4.250 2016-10-20 22:01:30  \n",
      "...         ...    ...    ...                 ...  \n",
      "3897 -97.733165      0  3.497 2016-10-20 23:14:31  \n",
      "3898 -97.733141      0  3.289 2016-10-20 23:14:32  \n",
      "3899 -97.733114      0  2.969 2016-10-20 23:14:33  \n",
      "3900 -97.733087      0  2.969 2016-10-20 23:14:34  \n",
      "3901 -97.733063      0  2.853 2016-10-20 23:14:35  \n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:1] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr   latitude  \\\n",
      "0              0  185.800003       51      3.460000   81  30.313309   \n",
      "1              1  185.800003       68      7.170000   82  30.313277   \n",
      "2              2  186.399994       38     11.040000   82  30.313243   \n",
      "3              3  186.800003       38     15.180000   83  30.313212   \n",
      "4              4  186.600006       38     19.430000   83  30.313172   \n",
      "...          ...         ...      ...           ...  ...        ...   \n",
      "3897        1127  178.199997        0  22014.929688  100  30.313483   \n",
      "3898        1128  178.199997        0  22018.220703  100  30.313482   \n",
      "3899        1129  178.199997        0  22021.179688  100  30.313485   \n",
      "3900        1130  178.399994        0  22024.150391  100  30.313489   \n",
      "3901        1131  178.399994        0  22027.009766  100  30.313492   \n",
      "\n",
      "      longitude  power  speed                time  \n",
      "0    -97.732711     45  3.459 2016-10-20 22:01:26  \n",
      "1    -97.732715      0  3.710 2016-10-20 22:01:27  \n",
      "2    -97.732717     42  3.874 2016-10-20 22:01:28  \n",
      "3    -97.732720      5  4.135 2016-10-20 22:01:29  \n",
      "4    -97.732723      1  4.250 2016-10-20 22:01:30  \n",
      "...         ...    ...    ...                 ...  \n",
      "3897 -97.733165      0  3.497 2016-10-20 23:14:31  \n",
      "3898 -97.733141      0  3.289 2016-10-20 23:14:32  \n",
      "3899 -97.733114      0  2.969 2016-10-20 23:14:33  \n",
      "3900 -97.733087      0  2.969 2016-10-20 23:14:34  \n",
      "3901 -97.733063      0  2.853 2016-10-20 23:14:35  \n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:2] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr   latitude  \\\n",
      "0              0  185.800003       51      3.460000   81  30.313309   \n",
      "1              1  185.800003       68      7.170000   82  30.313277   \n",
      "2              2  186.399994       38     11.040000   82  30.313243   \n",
      "3              3  186.800003       38     15.180000   83  30.313212   \n",
      "4              4  186.600006       38     19.430000   83  30.313172   \n",
      "...          ...         ...      ...           ...  ...        ...   \n",
      "3897        1127  178.199997        0  22014.929688  100  30.313483   \n",
      "3898        1128  178.199997        0  22018.220703  100  30.313482   \n",
      "3899        1129  178.199997        0  22021.179688  100  30.313485   \n",
      "3900        1130  178.399994        0  22024.150391  100  30.313489   \n",
      "3901        1131  178.399994        0  22027.009766  100  30.313492   \n",
      "\n",
      "      longitude  power  speed                time  \n",
      "0    -97.732711     45  3.459 2016-10-20 22:01:26  \n",
      "1    -97.732715      0  3.710 2016-10-20 22:01:27  \n",
      "2    -97.732717     42  3.874 2016-10-20 22:01:28  \n",
      "3    -97.732720      5  4.135 2016-10-20 22:01:29  \n",
      "4    -97.732723      1  4.250 2016-10-20 22:01:30  \n",
      "...         ...    ...    ...                 ...  \n",
      "3897 -97.733165      0  3.497 2016-10-20 23:14:31  \n",
      "3898 -97.733141      0  3.289 2016-10-20 23:14:32  \n",
      "3899 -97.733114      0  2.969 2016-10-20 23:14:33  \n",
      "3900 -97.733087      0  2.969 2016-10-20 23:14:34  \n",
      "3901 -97.733063      0  2.853 2016-10-20 23:14:35  \n",
      "\n",
      "[3902 rows x 10 columns]\n",
      "[stdout:3] \n",
      "      Unnamed: 0    altitude  cadence      distance   hr   latitude  \\\n",
      "0              0  185.800003       51      3.460000   81  30.313309   \n",
      "1              1  185.800003       68      7.170000   82  30.313277   \n",
      "2              2  186.399994       38     11.040000   82  30.313243   \n",
      "3              3  186.800003       38     15.180000   83  30.313212   \n",
      "4              4  186.600006       38     19.430000   83  30.313172   \n",
      "...          ...         ...      ...           ...  ...        ...   \n",
      "3897        1127  178.199997        0  22014.929688  100  30.313483   \n",
      "3898        1128  178.199997        0  22018.220703  100  30.313482   \n",
      "3899        1129  178.199997        0  22021.179688  100  30.313485   \n",
      "3900        1130  178.399994        0  22024.150391  100  30.313489   \n",
      "3901        1131  178.399994        0  22027.009766  100  30.313492   \n",
      "\n",
      "      longitude  power  speed                time  \n",
      "0    -97.732711     45  3.459 2016-10-20 22:01:26  \n",
      "1    -97.732715      0  3.710 2016-10-20 22:01:27  \n",
      "2    -97.732717     42  3.874 2016-10-20 22:01:28  \n",
      "3    -97.732720      5  4.135 2016-10-20 22:01:29  \n",
      "4    -97.732723      1  4.250 2016-10-20 22:01:30  \n",
      "...         ...    ...    ...                 ...  \n",
      "3897 -97.733165      0  3.497 2016-10-20 23:14:31  \n",
      "3898 -97.733141      0  3.289 2016-10-20 23:14:32  \n",
      "3899 -97.733114      0  2.969 2016-10-20 23:14:33  \n",
      "3900 -97.733087      0  2.969 2016-10-20 23:14:34  \n",
      "3901 -97.733063      0  2.853 2016-10-20 23:14:35  \n",
      "\n",
      "[3902 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return bodo.allgatherv(df)\n",
    "\n",
    "df = mean_power()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parallel I/O\n",
    "<img style=\"float: right;\" src=\"img/file-read.jpg\">\n",
    "\n",
    "Efficient parallel data processing requires data I/O to be parallelized effectively as well. Bodo provides parallel file I/O for many different formats such as [Parquet](http://parquet.apache.org),\n",
    "CSV, JSON, Numpy binaries, [HDF5](http://www.h5py.org) and SQL databases. This diagram demonstrates how chunks of data are partitioned among parallel execution engines by Bodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet\n",
    "\n",
    "Parquet is a commonly used file format in analytics due to its efficient columnar storage. Bodo supports the standard pandas API for reading Parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>altitude</th>\n",
       "      <th>cadence</th>\n",
       "      <th>distance</th>\n",
       "      <th>hr</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>power</th>\n",
       "      <th>speed</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>185.800003</td>\n",
       "      <td>51</td>\n",
       "      <td>3.46</td>\n",
       "      <td>81</td>\n",
       "      <td>30.313309</td>\n",
       "      <td>-97.732711</td>\n",
       "      <td>45</td>\n",
       "      <td>3.459</td>\n",
       "      <td>2016-10-20 22:01:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185.800003</td>\n",
       "      <td>68</td>\n",
       "      <td>7.17</td>\n",
       "      <td>82</td>\n",
       "      <td>30.313277</td>\n",
       "      <td>-97.732715</td>\n",
       "      <td>0</td>\n",
       "      <td>3.710</td>\n",
       "      <td>2016-10-20 22:01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>186.399994</td>\n",
       "      <td>38</td>\n",
       "      <td>11.04</td>\n",
       "      <td>82</td>\n",
       "      <td>30.313243</td>\n",
       "      <td>-97.732717</td>\n",
       "      <td>42</td>\n",
       "      <td>3.874</td>\n",
       "      <td>2016-10-20 22:01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>186.800003</td>\n",
       "      <td>38</td>\n",
       "      <td>15.18</td>\n",
       "      <td>83</td>\n",
       "      <td>30.313212</td>\n",
       "      <td>-97.732720</td>\n",
       "      <td>5</td>\n",
       "      <td>4.135</td>\n",
       "      <td>2016-10-20 22:01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>186.600006</td>\n",
       "      <td>38</td>\n",
       "      <td>19.43</td>\n",
       "      <td>83</td>\n",
       "      <td>30.313172</td>\n",
       "      <td>-97.732723</td>\n",
       "      <td>1</td>\n",
       "      <td>4.250</td>\n",
       "      <td>2016-10-20 22:01:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    altitude  cadence  distance  hr   latitude  longitude  power  \\\n",
       "0           0  185.800003       51      3.46  81  30.313309 -97.732711     45   \n",
       "1           1  185.800003       68      7.17  82  30.313277 -97.732715      0   \n",
       "2           2  186.399994       38     11.04  82  30.313243 -97.732717     42   \n",
       "3           3  186.800003       38     15.18  83  30.313212 -97.732720      5   \n",
       "4           4  186.600006       38     19.43  83  30.313172 -97.732723      1   \n",
       "\n",
       "   speed                time  \n",
       "0  3.459 2016-10-20 22:01:26  \n",
       "1  3.710 2016-10-20 22:01:27  \n",
       "2  3.874 2016-10-20 22:01:28  \n",
       "3  4.135 2016-10-20 22:01:29  \n",
       "4  4.250 2016-10-20 22:01:30  "
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "from IPython.display import display\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def pq_read():\n",
    "    df = pd.read_parquet('cycling_dataset.pq')\n",
    "    return df\n",
    "\n",
    "# on each process, this returns the data chunk read by that process\n",
    "res = pq_read()\n",
    "if bodo.get_rank() == 0:\n",
    "    display(res.head())  # display results of first process only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo also supports the pandas API for writing Parquet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def generate_data_and_write():\n",
    "    df = pd.DataFrame({\"A\": np.arange(80)})\n",
    "    df.to_parquet(\"pq_output.pq\")\n",
    "\n",
    "generate_data_and_write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"\n",
    "<b>Note:</b> Bodo writes a directory of parquet files (one file per process) when writing distributed data. Bodo writes a single file when the data is replicated.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `df` is distributed data so it is written to a directory a parquet files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo supports parallel read of single Parquet files, as well as directory of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "     A\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "6    6\n",
      "7    7\n",
      "8    8\n",
      "9    9\n",
      "10  10\n",
      "11  11\n",
      "12  12\n",
      "13  13\n",
      "14  14\n",
      "15  15\n",
      "16  16\n",
      "17  17\n",
      "18  18\n",
      "19  19\n",
      "20  20\n",
      "21  21\n",
      "22  22\n",
      "23  23\n",
      "24  24\n",
      "25  25\n",
      "26  26\n",
      "27  27\n",
      "28  28\n",
      "29  29\n",
      "30  30\n",
      "31  31\n",
      "32  32\n",
      "33  33\n",
      "34  34\n",
      "35  35\n",
      "36  36\n",
      "37  37\n",
      "38  38\n",
      "39  39\n",
      "[stdout:1] \n",
      "     A\n",
      "40  40\n",
      "41  41\n",
      "42  42\n",
      "43  43\n",
      "44  44\n",
      "45  45\n",
      "46  46\n",
      "47  47\n",
      "48  48\n",
      "49  49\n",
      "50  50\n",
      "51  51\n",
      "52  52\n",
      "53  53\n",
      "54  54\n",
      "55  55\n",
      "56  56\n",
      "57  57\n",
      "58  58\n",
      "59  59\n",
      "60  60\n",
      "61  61\n",
      "62  62\n",
      "63  63\n",
      "64  64\n",
      "65  65\n",
      "66  66\n",
      "67  67\n",
      "68  68\n",
      "69  69\n",
      "70  70\n",
      "71  71\n",
      "72  72\n",
      "73  73\n",
      "74  74\n",
      "75  75\n",
      "76  76\n",
      "77  77\n",
      "78  78\n",
      "79  79\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def read_parquet_dir():\n",
    "    df = pd.read_parquet(\"pq_output.pq\")\n",
    "    return df\n",
    "\n",
    "df = read_parquet_dir()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV\n",
    "CSV is a common text format for data exchange. Bodo supports the standard pandas API to read CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>185.8000030517578</th>\n",
       "      <th>51</th>\n",
       "      <th>3.4600000381469727</th>\n",
       "      <th>81</th>\n",
       "      <th>30.31330947764218</th>\n",
       "      <th>-97.73271068930626</th>\n",
       "      <th>45</th>\n",
       "      <th>3.4590001106262207</th>\n",
       "      <th>2016-10-20 22:01:26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>185.800003</td>\n",
       "      <td>68</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>82</td>\n",
       "      <td>30.313277</td>\n",
       "      <td>-97.732715</td>\n",
       "      <td>0</td>\n",
       "      <td>3.710</td>\n",
       "      <td>2016-10-20 22:01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>186.399994</td>\n",
       "      <td>38</td>\n",
       "      <td>11.040000</td>\n",
       "      <td>82</td>\n",
       "      <td>30.313243</td>\n",
       "      <td>-97.732717</td>\n",
       "      <td>42</td>\n",
       "      <td>3.874</td>\n",
       "      <td>2016-10-20 22:01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>186.800003</td>\n",
       "      <td>38</td>\n",
       "      <td>15.180000</td>\n",
       "      <td>83</td>\n",
       "      <td>30.313212</td>\n",
       "      <td>-97.732720</td>\n",
       "      <td>5</td>\n",
       "      <td>4.135</td>\n",
       "      <td>2016-10-20 22:01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>186.600006</td>\n",
       "      <td>38</td>\n",
       "      <td>19.430000</td>\n",
       "      <td>83</td>\n",
       "      <td>30.313172</td>\n",
       "      <td>-97.732723</td>\n",
       "      <td>1</td>\n",
       "      <td>4.250</td>\n",
       "      <td>2016-10-20 22:01:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>186.600006</td>\n",
       "      <td>0</td>\n",
       "      <td>23.860001</td>\n",
       "      <td>84</td>\n",
       "      <td>30.313130</td>\n",
       "      <td>-97.732724</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435</td>\n",
       "      <td>2016-10-20 22:01:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  185.8000030517578  51  3.4600000381469727  81  30.31330947764218  \\\n",
       "0  1    1         185.800003  68            7.170000  82          30.313277   \n",
       "1  2    2         186.399994  38           11.040000  82          30.313243   \n",
       "2  3    3         186.800003  38           15.180000  83          30.313212   \n",
       "3  4    4         186.600006  38           19.430000  83          30.313172   \n",
       "4  5    5         186.600006   0           23.860001  84          30.313130   \n",
       "\n",
       "   -97.73271068930626  45  3.4590001106262207  2016-10-20 22:01:26  \n",
       "0          -97.732715   0               3.710  2016-10-20 22:01:27  \n",
       "1          -97.732717  42               3.874  2016-10-20 22:01:28  \n",
       "2          -97.732720   5               4.135  2016-10-20 22:01:29  \n",
       "3          -97.732723   1               4.250  2016-10-20 22:01:30  \n",
       "4          -97.732724   0               4.435  2016-10-20 22:01:31  "
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(distributed=['df'])\n",
    "def csv_example():\n",
    "    df = pd.read_csv('cycling_dataset.csv')\n",
    "    return df\n",
    "\n",
    "res = csv_example()\n",
    "if bodo.get_rank() == 0:\n",
    "    display(res.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the pandas `read_csv()` functionality, Bodo can also read a directory containing multiple CSV files (all part of the same dataframe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"\n",
    "<b>Note:</b>\n",
    "\n",
    "When writing distributed data to CSV:\n",
    "- To S3 or HDFS: Bodo writes to a directory of CSV files (one file per process)\n",
    "- To POSIX filesystem (e.g. local filesystem on Linux): Bodo writes the distributed data in parallel to a single file.\n",
    "\n",
    "If the data is replicated, Bodo always writes to a single file.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5\n",
    "HDF5 is a common format in scientific computing, especially for multi-dimensional numerical data. HDF5 can be very efficient at scale, since it has native parallel I/O support. Bodo supports the standard h5py APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "import h5py\n",
    "\n",
    "@bodo.jit\n",
    "def example_h5():\n",
    "    f = h5py.File(\"data.h5\", \"r\")\n",
    "    return f['A'][:].sum()\n",
    "\n",
    "res = example_h5()\n",
    "if bodo.get_rank() == 0: print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Binary Files\n",
    "Bodo supports reading and writing binary files using Numpy APIs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def example_np_io():\n",
    "    A = np.fromfile(\"data.dat\", np.int64)\n",
    "    return A.sum()\n",
    "\n",
    "res = example_np_io()\n",
    "if bodo.get_rank() == 0: print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Annotation (when file name is unknown at compile time)\n",
    "\n",
    "Bodo needs to know or infer the types for all data, but this is not always possible for input from files if file name is not known at compilation time.\n",
    "\n",
    "For example, suppose we have the following files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_files(n):\n",
    "    for i in range(n):\n",
    "        df = pd.DataFrame({\"A\": np.arange(5, dtype=np.int64)})\n",
    "        df.to_parquet(\"test\" + str(i) + \".pq\")\n",
    "\n",
    "generate_files(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we want to read them like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "BodoError",
     "evalue": "Parquet schema not available. Either path argument should be constant for Bodo to look at the file at compile time or schema should be provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBodoError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ba2cf6e103a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbodo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bodo-master/bodo/compiler.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0margtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mForceLiteralArg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;31m# Received request for compiler re-entry with the list of arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_misses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                 \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mForceLiteralArg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mfolded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_cached\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_failed_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         cres = compiler.compile_extra(self.targetdescr.typing_context,\n\u001b[0m\u001b[1;32m    105\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetdescr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                                       \u001b[0mimpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    549\u001b[0m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[1;32m    550\u001b[0m                               args, return_type, flags, locals)\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \"\"\"\n\u001b[1;32m    392\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/compiler_machinery.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mpass_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pass_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompilerPass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Legacy pass in use\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/compiler_machinery.py\u001b[0m in \u001b[0;36m_runPass\u001b[0;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_initialization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpass_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfinalize_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_finalizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DEV/lib/python3.8/site-packages/numba/compiler_machinery.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(func, compiler_state)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiler_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mmangled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmangled\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 msg = (\"CompilerPass implementations should return True/False. \"\n",
      "\u001b[0;32m~/bodo-master/bodo/compiler.py\u001b[0m in \u001b[0;36mrun_pass\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         )\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0muntyped_pass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bodo-master/bodo/transforms/untyped_pass.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mout_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mout_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bodo-master/bodo/transforms/untyped_pass.py\u001b[0m in \u001b[0;36m_run_assign\u001b[0;34m(self, assign, label)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"call\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;31m# fix type for f['A'][:] dset reads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bodo-master/bodo/transforms/untyped_pass.py\u001b[0m in \u001b[0;36m_run_call\u001b[0;34m(self, assign, label)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfdef\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"read_parquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pandas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_pd_read_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfdef\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pandas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bodo-master/bodo/transforms/untyped_pass.py\u001b[0m in \u001b[0;36m_handle_pd_read_parquet\u001b[0;34m(self, assign, lhs, rhs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_const_val_or_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_parquet_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bodo-master/bodo/transforms/untyped_pass.py\u001b[0m in \u001b[0;36m_gen_parquet_read\u001b[0;34m(self, fname, lhs, columns)\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow is required for Parquet support\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         columns, data_arrs, index_col, nodes = self.pq_handler.gen_parquet_read(\n\u001b[0m\u001b[1;32m   1193\u001b[0m             \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         )\n",
      "\u001b[0;32m~/bodo-master/bodo/io/parquet_pio.py\u001b[0m in \u001b[0;36mgen_parquet_read\u001b[0;34m(self, file_name, lhs, columns)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;34m\"at compile time or schema should be provided.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             )\n\u001b[0;32m--> 117\u001b[0;31m             file_name_str = get_str_const_value(\n\u001b[0m\u001b[1;32m    118\u001b[0m                 \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             )\n",
      "\u001b[0;32m~/bodo-master/bodo/utils/transform.py\u001b[0m in \u001b[0;36mget_str_const_value\u001b[0;34m(var, func_ir, err_msg, typemap, arg_types)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_str_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypemap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mBodoError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBodoError\u001b[0m: Parquet schema not available. Either path argument should be constant for Bodo to look at the file at compile time or schema should be provided."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def read_data(n):\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"test\" + str(i) + \".pq\"\n",
    "        df = pd.read_parquet(file_name)\n",
    "        print(df)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "result = read_data(5)\n",
    "# BodoError: Parquet schema not available. Either path argument should be\n",
    "# constant for Bodo to look at the file at compile time or schema should be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file names are computed at runtime, which doesn't allow the compiler to find the files and extract the schemas. As shown below, the solution is to use *type annotation* to provide data types to the compiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type annotation for Parquet files\n",
    "\n",
    "Example below uses the `locals` option of the decorator to provide the compiler with the schema of the local variable `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 50\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(locals={\"df\": {\"A\": bodo.int64[:]}})\n",
    "def read_data(n):\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"test\" + str(i) + \".pq\"\n",
    "        df = pd.read_parquet(file_name)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "result = read_data(5)\n",
    "if bodo.get_rank() == 0:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type annotation for CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CSV files, we can annotate types in the same way as pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 50\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "def generate_files(n):\n",
    "    for i in range(n):\n",
    "        df = pd.DataFrame({\"A\": np.arange(5, dtype=np.int64)})\n",
    "        df.to_csv(\"test\" + str(i) + \".csv\", index=False)\n",
    "\n",
    "@bodo.jit\n",
    "def read_data(n):\n",
    "    coltypes = {'A': np.int64}\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"test\" + str(i) + \".csv\"\n",
    "        df = pd.read_csv(file_name, names=coltypes.keys(), dtype=coltypes, header=True)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "n = 5\n",
    "if bodo.get_rank() == 0:\n",
    "    generate_files(n)\n",
    "bodo.barrier()\n",
    "result = read_data(n)\n",
    "if bodo.get_rank() == 0:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Advanced Features\n",
    "\n",
    "## Explicit Parallel Loops\n",
    "Sometimes explicit parallel loops are required since a program cannot be written in terms of data-parallel operators easily. In this case, one can use Bodos `prange` in place of `range` to specify that a loop can be parallelized. The user is required to make sure the loop does not have cross iteration dependencies except for supported reductions.\n",
    "\n",
    "The example below demonstrates a parallel loop with a reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import bodo\n",
    "from bodo import prange\n",
    "import numpy as np\n",
    "\n",
    "@bodo.jit\n",
    "def prange_test(n):\n",
    "    A = np.random.ranf(n)\n",
    "    s = 0\n",
    "    for i in prange(len(A)):\n",
    "        # A[i]: distributed data access with loop index\n",
    "        # s: a supported sum reduction\n",
    "        s += A[i]\n",
    "    return s\n",
    "\n",
    "res = prange_test(10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, reductions using +=, *=, min, and max operators are supported. Iterations are simply divided between processes and executed in parallel, but reductions are handled using data exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with non-Bodo APIs\n",
    "There are multiple methods for integration with APIs that Bodo does not support natively:\n",
    "1. Switch to python object mode inside jit functions\n",
    "2. Pass data in and out of jit functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object mode\n",
    "Object mode allows switching to a python intepreted context to be able to run non-jittable code. The main requirement is specifying the type of returned values. For example, the following code calls a Scipy function on data elements of a distributed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import scipy.special as sc\n",
    "\n",
    "@bodo.jit\n",
    "def objmode_test(n):\n",
    "    A = np.random.ranf(n)\n",
    "    s = 0\n",
    "    for i in prange(len(A)):\n",
    "        x = A[i]\n",
    "        with bodo.objmode(y=\"float64\"):\n",
    "            y = sc.entr(x)  # call entropy function on each data element\n",
    "        s += y\n",
    "    return s\n",
    "\n",
    "res = objmode_test(10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Numba's documentation for [objmode](http://numba.pydata.org/numba-doc/latest/user/withobjmode.html#the-objmode-context-manager) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Distributed Data\n",
    "Bodo can receive or return chunks of distributed data to allow flexible integration with any non-Bodo Python code. The following example passes chunks of data to interpolate with Scipy, and returns interpolation results back to jit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import scipy.interpolate\n",
    "\n",
    "@bodo.jit(distributed=[\"X\", \"Y\", \"X2\"])\n",
    "def dist_pass_test(n):\n",
    "    X = np.arange(n)\n",
    "    Y = np.exp(-X/3.0)\n",
    "    X2 = np.arange(0, n, 0.5)\n",
    "    return X, Y, X2\n",
    "\n",
    "X, Y, X2 = dist_pass_test(100)\n",
    "# clip potential out-of-range values\n",
    "X2 = np.minimum(np.maximum(X2, X[0]), X[-1])\n",
    "f = scipy.interpolate.interp1d(X, Y)\n",
    "Y2 = f(X2)\n",
    "\n",
    "@bodo.jit(distributed={'Y2'})\n",
    "def dist_pass_res(Y2):\n",
    "    return Y2.sum()\n",
    "\n",
    "res = dist_pass_res(Y2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "A simple approach for visualization is pulling data to the notebook process from execution engines and using Python visualization libraries. Distributed data can be gathered if there is enough memory on the local machine. Otherwise, a sample of data can be gathered. The example code below demonstrates gathering a portion of data for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "\n",
    "@bodo.jit\n",
    "def dist_gather_test(n):\n",
    "    X = np.arange(n)\n",
    "    Y = np.exp(-X/3.0)\n",
    "    return bodo.gatherv(Y[::10])  # gather every 10th element\n",
    "\n",
    "\n",
    "Y_sample = dist_gather_test(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "Y_sample = view['Y_sample'][0]\n",
    "plt.plot(Y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Troubleshooting\n",
    "\n",
    "## Compilation Tips\n",
    "\n",
    "The general recommendation is to **compile the code that is performance critical and/or requires scaling**.\n",
    "\n",
    "1. Dont use Bodo for scripts that set up infrastucture or do initializations.\n",
    "2. Only use Bodo for data processing and analytics code.\n",
    "\n",
    "This reduces the risk of hitting unsupported features and reduces compilation time. To do so, simply factor out the code that needs to be compiled by Bodo and pass data into Bodo compiled functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation Errors\n",
    "\n",
    "The most common reason is that the code relies on features that Bodo currently does not support, so its important to understand the limitations of Bodo. There are 4 main limitations:\n",
    "\n",
    "1. Not supported Pandas API (see [here](http://docs.bodo.ai/latest/source/pandas.html#pandas))\n",
    "2. Not supported NumPy API (see [here](http://docs.bodo.ai/latest/source/numpy.html#numpy))\n",
    "3. Not supported Python features or datatypes (see [here](http://docs.bodo.ai/latest/source/not_supported.html#unsupported-python-constructs))\n",
    "4. Not supported Python programs due to type instability\n",
    "\n",
    "Solutions:\n",
    "\n",
    "1. Make sure your code works in Python (using a small sample dataset): a lot of the times a Bodo decorated function doesnt compile, but it does not compile in Python either.\n",
    "2. Replace unsupported operations with supported operations if possible.\n",
    "3. Refactor the code to partially use regular Python, explained in \"Integration with non-Bodo APIs\" section.\n",
    "\n",
    "For example, the code below uses heterogenous list values inside `a` which cannot be typed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f(n):\n",
    "    a = [[-1, \"a\"]]\n",
    "    for i in range(n):\n",
    "        a.append([i, \"a\"])\n",
    "    return a\n",
    "\n",
    "print(f(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this use case can be rewritten to use tuple values instead of lists since values don't change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f(n):\n",
    "    a = [(-1, \"a\")]\n",
    "    for i in range(n):\n",
    "        a.append((i, \"a\"))\n",
    "    return a\n",
    "\n",
    "print(f(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Schema Stability\n",
    "\n",
    "Deterministic dataframe schemas (column names and types), which are required in most data systems, are key for type stability. For example, variable `df` in example below could be either a single column dataframe or a two column one  Bodo cannot determine it at compilation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f(a):\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    df2 = pd.DataFrame({\"A\": [1, 3, 4], \"C\": [-1, -2, -3]})\n",
    "    if len(a) > 3:\n",
    "        df = df.merge(df2)\n",
    "\n",
    "    return df.mean()\n",
    "\n",
    "print(f([2, 3]))\n",
    "# TypeError: Cannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), False)\n",
    "# and dataframe((array(int64, 1d, C), array(int64, 1d, C)), RangeIndexType(none), ('A', 'C'), False) for 'df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message means that Bodo cannot find a type that can unify the two types into a single type. This code can be refactored so that the if control flow is executed in regular Python context, but the rest of computation is in Bodo functions. For example, one could use two versions of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f1():\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    return df.mean()\n",
    "\n",
    "@bodo.jit\n",
    "def f2():\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    df2 = pd.DataFrame({\"A\": [1, 3, 4], \"C\": [-1, -2, -3]})\n",
    "    df = df.merge(df2)\n",
    "    return df.mean()\n",
    "\n",
    "a = [2, 3]\n",
    "if len(a) > 3:\n",
    "    print(f1())\n",
    "else:\n",
    "    print(f2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common place where schema stability may be compromised is in passing non-constant list of key column names to dataframe operations such as `groupby`, `merge` and `sort_values`. In these operations, Bodo should be able to deduce the list of key column names at compile time in order to determine the output dataframe schema. For example, the program below is potentially type unstable since Bodo may not be able to infer `column_list` during compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def f(a):\n",
    "    column_list = a[0]  # some computation that cannot be inferred statically\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\n",
    "    return df.groupby(column_list).sum()\n",
    "\n",
    "f([\"A\"])\n",
    "# BodoError: groupby(): 'by' parameter only supports a constant column label or column labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nullable Integers in Pandas\n",
    "\n",
    "DataFrame and Series objects with integer data need special care due to [integer NA issues in Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#nan-integer-na-values-and-na-type-promotions). By default, Pandas dynamically converts integer columns to floating point when missing values (NAs) are needed, which can result in loss of precision as well as type instability.\n",
    "\n",
    "Pandas introduced [a new nullable integer data type](https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html#integer-na) that can solve this issue, which is also supported by Bodo. For example, this code reads column A into a nullable integer array (the capital I denotes nullable integer type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    \"11,1.2\\n\"\n",
    "    \"-2,\\n\"\n",
    "    \",3.1\\n\"\n",
    "    \"4,-0.1\\n\"\n",
    ")\n",
    "\n",
    "with open(\"data.csv\", \"w\") as f:\n",
    "    f.write(data)\n",
    "\n",
    "\n",
    "@bodo.jit(distributed=[\"df\"])\n",
    "def f():\n",
    "    dtype = {\"A\": \"Int64\", \"B\": \"float64\"}\n",
    "    df = pd.read_csv(\"data.csv\", dtype = dtype, names = dtype.keys())\n",
    "    return df\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxing/Unboxing Overheads\n",
    "\n",
    "Bodo uses efficient native data structures which can be different than Python. When Python values are passed to Bodo, they are *unboxed* to native representation. On the other hand, returning Bodo values requires *boxing* to Python objects. Boxing and unboxing can have significant overhead depending on size and type of data. For example, passing string column between Python/Bodo repeatedly can be expensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        2\n",
      "2        2\n",
      "3        3\n",
      "4        3\n",
      "        ..\n",
      "3897    00\n",
      "3898    00\n",
      "3899    00\n",
      "3900    00\n",
      "3901    00\n",
      "Name: hr, Length: 3902, dtype: object\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(distributed=[\"df\"])\n",
    "def gen_data():\n",
    "    df = pd.read_parquet(\"cycling_dataset.pq\")\n",
    "    df[\"hr\"] = df[\"hr\"].astype(str)\n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=[\"df\", \"x\"])\n",
    "def mean_power(df):\n",
    "    x = df.hr.str[1:]\n",
    "    return x\n",
    "\n",
    "df = gen_data()\n",
    "res = mean_power(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can try to keep data in Bodo functions as much as possible to avoid boxing/unboxing overheads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        2\n",
      "2        2\n",
      "3        3\n",
      "4        3\n",
      "        ..\n",
      "3897    00\n",
      "3898    00\n",
      "3899    00\n",
      "3900    00\n",
      "3901    00\n",
      "Name: hr, Length: 3902, dtype: object\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(distributed=[\"df\"])\n",
    "def gen_data():\n",
    "    df = pd.read_parquet(\"cycling_dataset.pq\")\n",
    "    df[\"hr\"] = df[\"hr\"].astype(str)\n",
    "    return df\n",
    "\n",
    "@bodo.jit(distributed=[\"df\", \"x\"])\n",
    "def mean_power(df):\n",
    "    x = df.hr.str[1:]\n",
    "    return x\n",
    "\n",
    "@bodo.jit\n",
    "def f():\n",
    "    df = gen_data()\n",
    "    res = mean_power(df)\n",
    "    print(res)\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
